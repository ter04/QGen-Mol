{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil, log2\n",
    "import re\n",
    "import pandas as pd\n",
    "import optax\n",
    "import csv\n",
    "import json\n",
    "import flax.linen as nn\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import qchem\n",
    "from pennylane.templates import StronglyEntanglingLayers\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn.initializers import normal\n",
    "\n",
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 32\n",
      "Bits per Token: 5\n",
      "Max Sequence Length: 31\n",
      "Alphabet: ['<SOS>', '[#Branch1]', '[#Branch2]', '[#C]', '[#N]', '[=Branch1]', '[=Branch2]', '[=C]', '[=N]', '[=O]', '[=PH1]', '[=P]', '[=Ring1]', '[=S]', '[Br]', '[Branch1]', '[Branch2]', '[C]', '[Cl]', '[F]', '[H]', '[I]', '[NH1]', '[N]', '[O]', '[PH1]', '[P]', '[Ring1]', '[Ring2]', '[S]', '<EOS>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from JSON\n",
    "N_MOLECS = 5000\n",
    "META_DATA_PATH = f\"../data/metadata_selfies_{N_MOLECS}.json\"\n",
    "\n",
    "with open(META_DATA_PATH, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "VOCABULARY_SIZE = metadata['vocabulary_size']\n",
    "BITS_PER_TOKEN = metadata['bits_per_token']\n",
    "MAX_LEN = metadata['max_sequence_length']\n",
    "ALPHABET = metadata['alphabet']\n",
    "min_logp = metadata['min_logP']\n",
    "max_logp = metadata['max_logP']\n",
    "min_qed = metadata['min_qed']\n",
    "max_qed = metadata['max_qed']\n",
    "min_mw = metadata['min_mw']\n",
    "max_mw = metadata['max_mw']\n",
    "\n",
    "print(\"Vocabulary Size:\", VOCABULARY_SIZE)\n",
    "print(\"Bits per Token:\", BITS_PER_TOKEN)\n",
    "print(\"Max Sequence Length:\", MAX_LEN)\n",
    "print(\"Alphabet:\", ALPHABET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Auxiliary functions ---\n",
    "\n",
    "def normalize(value, min_val, max_val, target_max=np.pi):\n",
    "    ''' Normalize a value to a range [0, [0, pi] to later encode them as rotation angles'''\n",
    "    norm = (value - min_val) / (max_val - min_val) * target_max\n",
    "    return float(f\"{norm:.3f}\")\n",
    "\n",
    "def token_to_index(token):\n",
    "    ''' Map a SELFIES token to its corresponding index in the ALPHABET'''\n",
    "    if token in ALPHABET:\n",
    "        return ALPHABET.index(token)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def bits_to_index(bits):\n",
    "    powers = 2 ** jnp.arange(len(bits) - 1, -1, -1)\n",
    "    return jnp.dot(bits, powers).astype(jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_index = token_to_index(\"<PAD>\")\n",
    "SOS_index = token_to_index(\"<SOS>\")\n",
    "EOS_index = token_to_index(\"<EOS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_bits_batch(csv_path, n_bits=BITS_PER_TOKEN):\n",
    "    \"\"\"\n",
    "    Read the dataset from a CSV file and convert it into bit representations for quantum processing.\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing the dataset.\n",
    "        n_bits (int): Number of bits used to represent each token.\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "            - X_bits (jnp.ndarray): Input bit representations of shape (N_Molecules, MAX_LEN-1, n_bits).\n",
    "            - Props (jnp.ndarray): Molecular properties of shape (N_Molecules, 3).\n",
    "            - Y_indices (jnp.ndarray): Target token indices of shape (N_Molecules, MAX_LEN-1).\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_path, dtype=str)\n",
    "    print(\"Dataset loaded with shape:\", df.shape)\n",
    "    \n",
    "    # Properties: logP, qed, mw\n",
    "    # Shape: (N_Moleculas, 3)\n",
    "    # Types: float\n",
    "    props = df.iloc[:, :3].astype(float).values\n",
    "    \n",
    "    # Tokens\n",
    "    # Shape: (N_Moleculas, MAX_LEN)\n",
    "    # Types: string (e.g., \"00101\")\n",
    "    token_cols = df.iloc[:, 3:].values\n",
    "    \n",
    "    # Auxiliary function to convert a string of '0's and '1's to a list\n",
    "    def str_to_bit_list(s):\n",
    "        return [int(c) for c in s]\n",
    "\n",
    "    # 3D array to hold all bits\n",
    "    all_bits = np.array([\n",
    "        [str_to_bit_list(token) for token in row] \n",
    "        for row in token_cols\n",
    "    ])\n",
    "    \n",
    "    # X_bits: Input for the model.\n",
    "    # Take all tokens except the last one.\n",
    "    X_bits = all_bits[:, :-1, :] \n",
    "    \n",
    "    # Y_ind: Target indices for the model.\n",
    "    # Take all tokens except the first one.\n",
    "    # Convert from bit strings to integer indices (for loss calculation).\n",
    "    Y_indices = np.array([[int(t, 2) for t in row[1:]] for row in token_cols])\n",
    "\n",
    "    return jnp.array(X_bits), jnp.array(props), jnp.array(Y_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with shape: (4777, 34)\n",
      "Loaded data:\n",
      "X_bits shape: (4777, 30, 5)\n",
      "Props shape: (4777, 3)\n",
      "Y_ind shape: (4777, 30)\n"
     ]
    }
   ],
   "source": [
    "MOLECS_DATA_PATH = f\"../data/structured_data_selfies_{N_MOLECS}.csv\"\n",
    "X_bits, Props, Y_ind = load_dataset_bits_batch(MOLECS_DATA_PATH)\n",
    "\n",
    "print(\"Loaded data:\")\n",
    "print(\"X_bits shape:\", X_bits.shape) # (N, L, 5)\n",
    "print(\"Props shape:\", Props.shape)   # (N, 3)\n",
    "print(\"Y_ind shape:\", Y_ind.shape)   # (N, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def zstring_combos(wires):\n",
    "    \"\"\"\n",
    "    Return an ordered list of wire-tuples for all Z-strings up to order H_LOCAL.\n",
    "    Order: all 1-local, then all 2-local, ..., up to H_LOCAL.\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    for k in range(1, H_LOCAL + 1):\n",
    "        L.extend(itertools.combinations(wires, k))\n",
    "    return [tuple(c) for c in L]\n",
    "\n",
    "def num_zstrings(n_wires):\n",
    "    \"\"\"Count how many Z-strings up to order H_LOCAL.\"\"\"\n",
    "    from math import comb\n",
    "    return sum(comb(n_wires, k) for k in range(1, H_LOCAL + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device and qubit setup\n",
    "# BITS_PER_TOKEN number of qubits needed to encode each token\n",
    "n_prop_qubits = 3  # number of qubits needed to encode properties (logP, QED, MW)\n",
    "n_ancillas = 3  # number of ancilla qubits that represent the environment\n",
    "n_total_qubits = n_prop_qubits + BITS_PER_TOKEN + n_ancillas\n",
    "\n",
    "N_LAYERS = 6  # number of variational layers\n",
    "H_LOCAL = 3 # h_local sets the maximum number of qubits that can interact in each Z-string term of Σ\n",
    "\n",
    "\n",
    "# Name them explicitly\n",
    "prop_wires = [f\"prop_{i}\" for i in range(n_prop_qubits)]\n",
    "token_wires = [f\"token_{i}\" for i in range(BITS_PER_TOKEN)]\n",
    "ancilla_wires = [f\"ancilla_{i}\" for i in range(n_ancillas)]\n",
    "all_wires = prop_wires + token_wires + ancilla_wires\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=all_wires)\n",
    "\n",
    "\n",
    "def molecular_property_encoder(props):\n",
    "    \"\"\"Encode continuous props on property qubits via RY rotations\"\"\"\n",
    "    for wire, val in zip(prop_wires, props):\n",
    "        qml.RY(val, wires=wire)\n",
    "\n",
    "\n",
    "def token_encoder(token_bits):\n",
    "    qml.BasisState(token_bits, wires=token_wires)\n",
    "\n",
    "\n",
    "def operator_layer(theta_params, theta_prop, wires):\n",
    "    \"\"\"\n",
    "    Variational layer where:\n",
    "      - theta_params[...] are rotations for token + ancilla qubits\n",
    "      - theta_prop encodes property→token entanglement\n",
    "    \"\"\"\n",
    "    prop_ws = prop_wires\n",
    "    token_ancilla_ws = token_wires + ancilla_wires\n",
    "\n",
    "    # Property → token entanglement\n",
    "    for p, prop_wire in enumerate(prop_ws):\n",
    "        for t, t_a_wire in enumerate(token_ancilla_ws):\n",
    "            qml.CRX(theta_prop[p, t, 0], wires=[prop_wire, t_a_wire])\n",
    "            qml.CRY(theta_prop[p, t, 1], wires=[prop_wire, t_a_wire])\n",
    "\n",
    "    # Single-qubit rotations\n",
    "        ''' for i, wire in enumerate(token_ancilla_ws):\n",
    "        qml.RX(theta_params[i, 0], wires=wire)\n",
    "        qml.RY(theta_params[i, 1], wires=wire)\n",
    "        qml.RZ(theta_params[i, 2], wires=wire)\n",
    "\n",
    "    # Entangle token + ancilla chain\n",
    "    for i in range(len(token_ancilla_ws) - 1):\n",
    "        qml.CNOT(wires=[token_ancilla_ws[i], token_ancilla_ws[i + 1]])\n",
    "    qml.CNOT(wires=[token_ancilla_ws[-1], token_ancilla_ws[0]])'''\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(\n",
    "        weights=theta_params[None,:,:],  # shape: (n_token_ancilla, 3)\n",
    "        wires=token_ancilla_ws\n",
    "    )\n",
    "\n",
    "def Sigma_layer_vec(gamma_vec, wires, time=1.0, combos=None):\n",
    "    \"\"\"\n",
    "    Diagonal multi-Z unitary Σ = exp(i * sum_s gamma_s * Z^{⊗|s|} * t)\n",
    "    using a flat parameter vector 'gamma_vec' aligned with 'combos'.\n",
    "    \"\"\"\n",
    "    token_ancilla_ws = list(wires)  # pass token+ancilla here\n",
    "    if combos is None:\n",
    "        combos = zstring_combos(token_ancilla_ws)\n",
    "\n",
    "    # Safety: ensure the vector length matches the number of combos\n",
    "    assert gamma_vec.shape[0] == len(combos), \\\n",
    "        f\"gamma_vec has length {gamma_vec.shape[0]} but expected {len(combos)}\"\n",
    "\n",
    "    # MultiRZ(phi) = exp(-i * phi/2 * Z^{⊗k}); choose phi = -2 * gamma * time\n",
    "    for gamma, combo in zip(gamma_vec, combos):\n",
    "        qml.MultiRZ(-2.0 * gamma * time, wires=list(combo))\n",
    "\n",
    "\n",
    "# QNode combining encoding and variational layers\n",
    "@qml.qnode(dev, interface=\"jax\")\n",
    "def autoregressive_model(token_bits, props, theta_params, theta_prop, sigma_params):\n",
    "    molecular_property_encoder(props)      # Encode MW, logP, QED\n",
    "    token_encoder(token_bits)              # Basis-encode token bits\n",
    "\n",
    "    token_ancilla_ws = token_wires + ancilla_wires\n",
    "    combos = zstring_combos(token_ancilla_ws)\n",
    "\n",
    "\n",
    "    for l in range(N_LAYERS):\n",
    "        # Forward V(θ)\n",
    "        operator_layer(theta_params[l], theta_prop[l], wires=all_wires)\n",
    "\n",
    "        # Diagonal Σ(γ,t): vector API\n",
    "        Sigma_layer_vec(sigma_params[l], token_ancilla_ws, time=1.0, combos=combos)\n",
    "\n",
    "        # Backward V(θ)†\n",
    "        qml.adjoint(operator_layer)(theta_params[l], theta_prop[l], wires=all_wires)\n",
    "\n",
    "    return qml.probs(wires=token_wires), [qml.expval(qml.PauliZ(w)) for w in prop_wires]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def bitstr_to_array(bitstr):\n",
    "    \"\"\"Convert a string of bits (e.g., '010101') to a numpy float32 array.\"\"\"\n",
    "    return np.array([int(b) for b in bitstr], dtype=np.float32)\n",
    "\n",
    "def build_training_data(df):\n",
    "    \"\"\"\n",
    "    Build dataset tuples of (input_token_bits, molecular_properties, target_token_bits)\n",
    "    from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing molecular properties and token bit strings.\n",
    "        n_token_cols (int): Number of token columns in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (x_token: np.array, x_props: np.array, y_target: np.array)\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract molecular properties as a numpy float32 array\n",
    "        props = [row['logP'], row['qed'], row['mw']]\n",
    "        x_props = np.array(props, dtype=np.float32)\n",
    "\n",
    "        tokens = row[3:]  # token columns after properties\n",
    "\n",
    "        # Iterate over token sequence to create input-target pairs\n",
    "        for i in range(len(tokens) - 1):\n",
    "            current_token = tokens.iloc[i]\n",
    "            next_token = tokens.iloc[i + 1]\n",
    "\n",
    "            # Skip missing or NaN tokens\n",
    "            if current_token is None or (isinstance(current_token, float) and math.isnan(current_token)):\n",
    "                continue\n",
    "            if next_token is None or (isinstance(next_token, float) and math.isnan(next_token)):\n",
    "                continue\n",
    "\n",
    "            # Convert token strings (e.g., '01011') to bit arrays\n",
    "            x_token = bitstr_to_array(current_token)\n",
    "            y_target = bitstr_to_array(next_token)\n",
    "\n",
    "            dataset.append((x_token, x_props, y_target))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "token_cols = [f\"token_{i}\" for i in range(n_tokens)]\n",
    "df = pd.read_csv(DATA_PATH, dtype={col: str for col in token_cols})\n",
    "dataset = build_training_data(df)  # Should return list/array of (x_token, x_props, y_target)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the embedding network function\n",
    "def embedding_network_fn(x):\n",
    "    embedding_size = N_LAYERS * (BITS_PER_TOKEN + n_ancillas) * 3 \n",
    "    mlp = hk.Sequential([\n",
    "        hk.Linear(32), jax.nn.relu,\n",
    "        hk.Linear(16), jax.nn.relu,\n",
    "        hk.Linear(embedding_size),  # Match θ shape\n",
    "    ])\n",
    "    return mlp(x)\n",
    "\n",
    "# 2. Transform the function to make it usable in JAX/Haiku\n",
    "embedding_network = hk.transform(embedding_network_fn)\n",
    "\n",
    "\n",
    "# 3. Use the embedding to generate θ parameters\n",
    "def get_context_embedding(prev_token_bits, embed_params):\n",
    "    \"\"\"\n",
    "    prev_token_bits: jnp.array of shape (12,) — concatenated 2×6 bits\n",
    "    Returns: reshaped embedding output to match θ shape\n",
    "    \"\"\"\n",
    "    embedding_output = embedding_network.apply(embed_params, None, prev_token_bits)\n",
    "    return embedding_output.reshape((N_LAYERS, BITS_PER_TOKEN + n_ancillas, 3))  # Shape for operator_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_to_index(bits):\n",
    "    powers = 2 ** jnp.arange(len(bits) - 1, -1, -1)\n",
    "    return jnp.dot(bits, powers).astype(jnp.int32)\n",
    "'''\n",
    "def categorical_crossentropy(pred_probs, target_index):\n",
    "    epsilon = 1e-10\n",
    "    return -jnp.log(pred_probs[target_index] + epsilon)\n",
    "\n",
    "def label_smoothing_crossentropy_normalized(pred_probs, target_index, epsilon=0.1, alpha=0.1):\n",
    "    \"\"\"Cross-entropy loss with label smoothing, normalized to [0,1].\"\"\"\n",
    "    num_classes = pred_probs.shape[0] # Number of classes (tokens)\n",
    "    \n",
    "    # Build smoothed target\n",
    "    smooth_target = jnp.full_like(pred_probs, epsilon / (num_classes - 1))\n",
    "    smooth_target = smooth_target.at[target_index].set(1.0 - epsilon)\n",
    "    \n",
    "    # Compute cross-entropy loss\n",
    "    ce_loss = -jnp.sum(smooth_target * jnp.log(pred_probs + 1e-10)) # in [0, log(num_classes)]\n",
    "    max_loss = jnp.log(num_classes)\n",
    "    total_loss = ce_loss / max_loss  # Normalize to [0,1]\n",
    "\n",
    "    return total_loss'''\n",
    "def total_loss_fn(pred_probs, prop_expvals, target_index, props, alpha=0.5, epsilon=0.1):\n",
    "    \"\"\"Single normalized loss in [0,1].\"\"\"\n",
    "    num_classes = pred_probs.shape[0]\n",
    "\n",
    "    # --- Cross-entropy with label smoothing (raw, not normalized yet) ---\n",
    "    smooth_target = jnp.full_like(pred_probs, epsilon / (num_classes - 1))\n",
    "    smooth_target = smooth_target.at[target_index].set(1.0 - epsilon)\n",
    "    ce_loss = -jnp.sum(smooth_target * jnp.log(pred_probs + 1e-10))  # in [0, log(num_classes)]\n",
    "\n",
    "    # --- Property preservation loss (MSE) ---\n",
    "    prop_expvals = jnp.array(prop_expvals)  # convert list -> JAX array\n",
    "    prop_loss = jnp.mean((prop_expvals - jnp.cos(props)) ** 2)  # in [0,4]\n",
    "\n",
    "    # --- Combine ---\n",
    "    combined_loss = ce_loss + alpha * prop_loss\n",
    "\n",
    "    # --- Normalize only once ---\n",
    "    max_loss = jnp.log(num_classes) + alpha * 4.0\n",
    "    final_loss = combined_loss / max_loss\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "def compute_accuracy(pred_probs, target_index):\n",
    "    predicted_index = jnp.argmax(pred_probs)\n",
    "    return jnp.array(predicted_index == target_index, dtype=jnp.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ter/Apps/anaconda3/envs/tfm/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
      "/Users/ter/Apps/anaconda3/envs/tfm/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.complex128'> requested in astype is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss = 0.5476 | Accuracy = 0.4380\n",
      "Epoch 2 | Loss = 0.5016 | Accuracy = 0.4766\n",
      "Epoch 3 | Loss = 0.4801 | Accuracy = 0.5086\n",
      "Epoch 4 | Loss = 0.4711 | Accuracy = 0.5244\n",
      "Epoch 5 | Loss = 0.4642 | Accuracy = 0.5353\n",
      "Epoch 6 | Loss = 0.4627 | Accuracy = 0.5375\n",
      "Epoch 7 | Loss = 0.4607 | Accuracy = 0.5381\n",
      "Epoch 8 | Loss = 0.4559 | Accuracy = 0.5449\n",
      "Epoch 9 | Loss = 0.4504 | Accuracy = 0.5526\n",
      "Epoch 10 | Loss = 0.4500 | Accuracy = 0.5562\n",
      "Epoch 11 | Loss = 0.4484 | Accuracy = 0.5641\n",
      "Epoch 12 | Loss = 0.4450 | Accuracy = 0.5685\n",
      "Epoch 13 | Loss = 0.4430 | Accuracy = 0.5686\n",
      "Epoch 14 | Loss = 0.4428 | Accuracy = 0.5658\n",
      "Epoch 15 | Loss = 0.4396 | Accuracy = 0.5706\n",
      "Epoch 16 | Loss = 0.4393 | Accuracy = 0.5747\n",
      "Epoch 17 | Loss = 0.4414 | Accuracy = 0.5708\n",
      "Epoch 18 | Loss = 0.4397 | Accuracy = 0.5716\n",
      "Epoch 19 | Loss = 0.4398 | Accuracy = 0.5763\n",
      "Epoch 20 | Loss = 0.4399 | Accuracy = 0.5767\n",
      "Epoch 21 | Loss = 0.4415 | Accuracy = 0.5756\n",
      "Epoch 22 | Loss = 0.4367 | Accuracy = 0.5796\n",
      "Epoch 23 | Loss = 0.4352 | Accuracy = 0.5825\n",
      "Epoch 24 | Loss = 0.4356 | Accuracy = 0.5808\n",
      "Epoch 25 | Loss = 0.4349 | Accuracy = 0.5789\n",
      "Epoch 26 | Loss = 0.4333 | Accuracy = 0.5784\n",
      "Epoch 27 | Loss = 0.4365 | Accuracy = 0.5749\n",
      "Epoch 28 | Loss = 0.4381 | Accuracy = 0.5726\n",
      "Epoch 29 | Loss = 0.4366 | Accuracy = 0.5738\n",
      "Epoch 30 | Loss = 0.4341 | Accuracy = 0.5746\n",
      "Epoch 31 | Loss = 0.4335 | Accuracy = 0.5762\n",
      "Epoch 32 | Loss = 0.4337 | Accuracy = 0.5804\n",
      "Epoch 33 | Loss = 0.4326 | Accuracy = 0.5744\n",
      "Epoch 34 | Loss = 0.4340 | Accuracy = 0.5768\n",
      "Epoch 35 | Loss = 0.4358 | Accuracy = 0.5772\n",
      "Epoch 36 | Loss = 0.4347 | Accuracy = 0.5778\n",
      "Epoch 37 | Loss = 0.4337 | Accuracy = 0.5790\n",
      "Epoch 38 | Loss = 0.4337 | Accuracy = 0.5778\n",
      "Epoch 39 | Loss = 0.4326 | Accuracy = 0.5774\n",
      "Epoch 40 | Loss = 0.4309 | Accuracy = 0.5825\n",
      "Epoch 41 | Loss = 0.4339 | Accuracy = 0.5780\n",
      "Epoch 42 | Loss = 0.4329 | Accuracy = 0.5807\n",
      "Epoch 43 | Loss = 0.4324 | Accuracy = 0.5839\n",
      "Epoch 44 | Loss = 0.4322 | Accuracy = 0.5842\n",
      "Epoch 45 | Loss = 0.4321 | Accuracy = 0.5829\n",
      "Epoch 46 | Loss = 0.4286 | Accuracy = 0.5882\n",
      "Epoch 47 | Loss = 0.4297 | Accuracy = 0.5895\n",
      "Epoch 48 | Loss = 0.4313 | Accuracy = 0.5833\n",
      "Epoch 49 | Loss = 0.4297 | Accuracy = 0.5902\n",
      "Epoch 50 | Loss = 0.4286 | Accuracy = 0.5883\n",
      "Epoch 51 | Loss = 0.4264 | Accuracy = 0.5897\n",
      "Epoch 52 | Loss = 0.4265 | Accuracy = 0.5904\n",
      "Epoch 53 | Loss = 0.4249 | Accuracy = 0.5953\n",
      "Epoch 54 | Loss = 0.4247 | Accuracy = 0.5906\n",
      "Epoch 55 | Loss = 0.4280 | Accuracy = 0.5864\n",
      "Epoch 56 | Loss = 0.4262 | Accuracy = 0.5893\n",
      "Epoch 57 | Loss = 0.4282 | Accuracy = 0.5885\n",
      "Epoch 58 | Loss = 0.4273 | Accuracy = 0.5867\n",
      "Epoch 59 | Loss = 0.4270 | Accuracy = 0.5827\n",
      "Epoch 60 | Loss = 0.4258 | Accuracy = 0.5903\n",
      "Epoch 61 | Loss = 0.4277 | Accuracy = 0.5873\n",
      "Epoch 62 | Loss = 0.4258 | Accuracy = 0.5911\n",
      "Epoch 63 | Loss = 0.4237 | Accuracy = 0.5920\n",
      "Epoch 64 | Loss = 0.4233 | Accuracy = 0.5943\n",
      "Epoch 65 | Loss = 0.4255 | Accuracy = 0.5891\n",
      "Epoch 66 | Loss = 0.4254 | Accuracy = 0.5888\n",
      "Epoch 67 | Loss = 0.4258 | Accuracy = 0.5931\n",
      "Epoch 68 | Loss = 0.4274 | Accuracy = 0.5882\n",
      "Epoch 69 | Loss = 0.4251 | Accuracy = 0.5901\n",
      "Epoch 70 | Loss = 0.4251 | Accuracy = 0.5931\n",
      "Epoch 71 | Loss = 0.4213 | Accuracy = 0.5972\n",
      "Epoch 72 | Loss = 0.4239 | Accuracy = 0.5905\n",
      "Epoch 73 | Loss = 0.4229 | Accuracy = 0.5898\n",
      "Epoch 74 | Loss = 0.4221 | Accuracy = 0.5942\n",
      "Epoch 75 | Loss = 0.4222 | Accuracy = 0.5925\n",
      "Epoch 76 | Loss = 0.4229 | Accuracy = 0.5933\n",
      "Epoch 77 | Loss = 0.4241 | Accuracy = 0.5936\n",
      "Epoch 78 | Loss = 0.4249 | Accuracy = 0.5927\n",
      "Epoch 79 | Loss = 0.4240 | Accuracy = 0.5903\n",
      "Epoch 80 | Loss = 0.4230 | Accuracy = 0.5939\n",
      "Epoch 81 | Loss = 0.4226 | Accuracy = 0.5938\n",
      "Epoch 82 | Loss = 0.4225 | Accuracy = 0.5958\n",
      "Epoch 83 | Loss = 0.4234 | Accuracy = 0.5935\n",
      "Epoch 84 | Loss = 0.4221 | Accuracy = 0.5968\n",
      "Epoch 85 | Loss = 0.4220 | Accuracy = 0.5968\n",
      "Epoch 86 | Loss = 0.4230 | Accuracy = 0.5941\n",
      "Epoch 87 | Loss = 0.4229 | Accuracy = 0.5927\n",
      "Epoch 88 | Loss = 0.4218 | Accuracy = 0.5964\n",
      "Epoch 89 | Loss = 0.4214 | Accuracy = 0.5959\n",
      "Epoch 90 | Loss = 0.4224 | Accuracy = 0.5952\n",
      "Epoch 91 | Loss = 0.4216 | Accuracy = 0.5956\n",
      "Epoch 92 | Loss = 0.4219 | Accuracy = 0.5974\n",
      "Epoch 93 | Loss = 0.4206 | Accuracy = 0.5965\n",
      "Epoch 94 | Loss = 0.4215 | Accuracy = 0.5950\n",
      "Epoch 95 | Loss = 0.4227 | Accuracy = 0.5974\n",
      "Epoch 96 | Loss = 0.4209 | Accuracy = 0.5981\n",
      "Epoch 97 | Loss = 0.4210 | Accuracy = 0.5975\n",
      "Epoch 98 | Loss = 0.4225 | Accuracy = 0.5971\n",
      "Epoch 99 | Loss = 0.4221 | Accuracy = 0.5960\n",
      "Epoch 100 | Loss = 0.4222 | Accuracy = 0.5967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m combined_params, loss, opt_state, grads, acc \u001b[38;5;241m=\u001b[39m training_step(combined_params, opt_state, x_token, x_props, y_target, context_vector)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Update previous tokens\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39marray_equal(x_token, EOS_token):\n\u001b[1;32m     90\u001b[0m     prev_token1 \u001b[38;5;241m=\u001b[39m SOS_token\n\u001b[1;32m     91\u001b[0m     prev_token2 \u001b[38;5;241m=\u001b[39m SOS_token\n",
      "File \u001b[0;32m~/Apps/anaconda3/envs/tfm/lib/python3.10/site-packages/jax/_src/array.py:306\u001b[0m, in \u001b[0;36mArrayImpl.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    305\u001b[0m   core\u001b[38;5;241m.\u001b[39mcheck_bool_conversion(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 306\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m)\n",
      "File \u001b[0;32m~/Apps/anaconda3/envs/tfm/lib/python3.10/site-packages/jax/_src/profiler.py:354\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    353\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Apps/anaconda3/envs/tfm/lib/python3.10/site-packages/jax/_src/array.py:644\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    643\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharding\u001b[38;5;241m.\u001b[39m_internal_device_list\u001b[38;5;241m.\u001b[39maddressable_device_list):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m     npy_value, did_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_device_array_to_np_array_did_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     npy_value\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m did_copy:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize embedding params\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dummy_context = jnp.zeros((3 * BITS_PER_TOKEN,), dtype=jnp.float32)  # 3 prev. tokens\n",
    "embedding_params = embedding_network.init(rng, dummy_context)\n",
    "\n",
    "# Effective qubit counts in variational layers\n",
    "n_token_ancilla = BITS_PER_TOKEN + n_ancillas\n",
    "\n",
    "# Initialize theta and sigma params\n",
    "key = jax.random.PRNGKey(42)\n",
    "key, k_theta, k_theta_prop, k_sigma = jax.random.split(key, 4)\n",
    "\n",
    "# Precompute Z-string combos once\n",
    "token_ancilla_ws = token_wires + ancilla_wires\n",
    "combos = zstring_combos(token_ancilla_ws)\n",
    "n_strings = len(combos)\n",
    "\n",
    "\n",
    "combined_params = {\n",
    "    'theta': jax.random.normal(k_theta, (N_LAYERS, n_token_ancilla, 3)) * 0.1,\n",
    "    'theta_prop': jax.random.normal(k_theta_prop, (N_LAYERS, n_prop_qubits, n_token_ancilla, 4)) * 0.1,\n",
    "    'sigma': jax.random.normal(k_sigma, (N_LAYERS, n_strings)) * 0.1,\n",
    "    'embedding': embedding_params,\n",
    "}\n",
    "# Training hyperparams\n",
    "learning_rate = 0.001\n",
    "n_epochs = 100\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(combined_params)\n",
    "\n",
    "@jax.jit\n",
    "def training_step(params, opt_state, x_token, x_props, y_target, context_vector):\n",
    "    def loss_fn(params):\n",
    "        theta_params = params['theta']\n",
    "        theta_prop = params['theta_prop']\n",
    "        sigma_params = params['sigma']\n",
    "        embedding_params = params['embedding']\n",
    "\n",
    "        # Embedding → adjustment for theta\n",
    "        theta_from_embedding = get_context_embedding(context_vector, embedding_params)\n",
    "        theta_effective = theta_params + theta_from_embedding\n",
    "        # theta_params || theta_from_embedding\n",
    "\n",
    "        # Predict\n",
    "        pred_probs, expval_props = autoregressive_model(x_token, x_props, theta_effective, theta_prop, sigma_params)\n",
    "        index = bits_to_index(y_target)\n",
    "        \n",
    "        # Return scalar loss for gradient computation\n",
    "        # return label_smoothing_crossentropy_nortotal_loss_fnmalized(pred_probs, index), pred_probs\n",
    "        return total_loss_fn(pred_probs, expval_props, index, x_props), pred_probs\n",
    "\n",
    "    # value_and_grad computes both loss and grads in one pass\n",
    "    (loss, pred_probs), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
    "\n",
    "    # Update parameters\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "    # Accuracy from pred_probs (already computed!)\n",
    "    index = bits_to_index(y_target)\n",
    "    acc = compute_accuracy(pred_probs, index)\n",
    "\n",
    "    return new_params, loss, opt_state, grads, acc\n",
    "\n",
    "# Context initialization outside epoch loop\n",
    "SOS_token = jnp.zeros((BITS_PER_TOKEN,), dtype=jnp.int32)\n",
    "eos_index = len(alphabet)-1\n",
    "EOS_token = jnp.array([int(b) for b in format(eos_index, f'0{BITS_PER_TOKEN}b')], dtype=jnp.int32)\n",
    "\n",
    "prev_token1 = SOS_token\n",
    "prev_token2 = SOS_token\n",
    "prev_token3 = SOS_token\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = total_acc = 0.0\n",
    "    \n",
    "    for x_token, x_props, y_target in dataset:\n",
    "        x_token = jnp.array(x_token, dtype=jnp.int32)\n",
    "        x_props = jnp.array(x_props, dtype=jnp.float32)\n",
    "        y_target = jnp.array(y_target, dtype=jnp.int32)\n",
    "      \n",
    "        context_vector = jnp.concatenate([prev_token1, prev_token2, prev_token3])\n",
    "\n",
    "        combined_params, loss, opt_state, grads, acc = training_step(combined_params, opt_state, x_token, x_props, y_target, context_vector)\n",
    "        \n",
    "        # Update previous tokens\n",
    "        if jnp.array_equal(x_token, EOS_token):\n",
    "            prev_token1 = SOS_token\n",
    "            prev_token2 = SOS_token\n",
    "            prev_token3 = SOS_token\n",
    "        else:\n",
    "            # Shift prev tokens, add current token as the newest previous token\n",
    "            prev_token3 = prev_token2\n",
    "            prev_token2 = prev_token1\n",
    "            prev_token1 = x_token\n",
    "\n",
    "        total_loss += loss\n",
    "        total_acc  += acc\n",
    "\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    avg_acc  = total_acc / len(dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Loss = {avg_loss:.4f} | Accuracy = {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jax.jit\n",
    "def training_step(params, opt_state, x_token, x_props, y_target, context_vector):\n",
    "    def loss_fn(params):\n",
    "        theta_params = params['theta']\n",
    "        theta_prop = params['theta_prop']\n",
    "        sigma_params = params['sigma']\n",
    "        embedding_params = params['embedding']\n",
    "\n",
    "        # Embedding → adjustment for theta\n",
    "        theta_from_embedding = get_context_embedding(context_vector, embedding_params)\n",
    "        theta_effective = theta_params + theta_from_embedding\n",
    "        # theta_params || theta_from_embedding\n",
    "\n",
    "        # Predict\n",
    "        pred_probs, expval_props = autoregressive_model(x_token, x_props, theta_effective, theta_prop, sigma_params)\n",
    "        index = bits_to_index(y_target)\n",
    "        \n",
    "        # Return scalar loss for gradient computation\n",
    "        # return label_smoothing_crossentropy_nortotal_loss_fnmalized(pred_probs, index), pred_probs\n",
    "        return total_loss_fn(pred_probs, expval_props, index, x_props), pred_probs\n",
    "\n",
    "    # value_and_grad computes both loss and grads in one pass\n",
    "    (loss, pred_probs), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
    "\n",
    "    # Update parameters\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "\n",
    "    # Accuracy from pred_probs (already computed!)\n",
    "    index = bits_to_index(y_target)\n",
    "    acc = compute_accuracy(pred_probs, index)\n",
    "\n",
    "    return new_params, loss, opt_state, grads, acc\n",
    "\n",
    "# Context initialization outside epoch loop\n",
    "SOS_token = jnp.zeros((BITS_PER_TOKEN,), dtype=jnp.int32)\n",
    "eos_index = len(alphabet)-1\n",
    "EOS_token = jnp.array([int(b) for b in format(eos_index, f'0{BITS_PER_TOKEN}b')], dtype=jnp.int32)\n",
    "\n",
    "prev_token1 = SOS_token\n",
    "prev_token2 = SOS_token\n",
    "prev_token3 = SOS_token\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = total_acc = 0.0\n",
    "    \n",
    "    for x_token, x_props, y_target in dataset:\n",
    "        x_token = jnp.array(x_token, dtype=jnp.int32)\n",
    "        x_props = jnp.array(x_props, dtype=jnp.float32)\n",
    "        y_target = jnp.array(y_target, dtype=jnp.int32)\n",
    "      \n",
    "        context_vector = jnp.concatenate([prev_token1, prev_token2, prev_token3])\n",
    "\n",
    "        combined_params, loss, opt_state, grads, acc = training_step(combined_params, opt_state, x_token, x_props, y_target, context_vector)\n",
    "        \n",
    "        # Update previous tokens\n",
    "        if jnp.array_equal(x_token, EOS_token):\n",
    "            prev_token1 = SOS_token\n",
    "            prev_token2 = SOS_token\n",
    "            prev_token3 = SOS_token\n",
    "        else:\n",
    "            # Shift prev tokens, add current token as the newest previous token\n",
    "            prev_token3 = prev_token2\n",
    "            prev_token2 = prev_token1\n",
    "            prev_token1 = x_token\n",
    "\n",
    "        total_loss += loss\n",
    "        total_acc  += acc\n",
    "\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    avg_acc  = total_acc / len(dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Loss = {avg_loss:.4f} | Accuracy = {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory path (relative to your current location, assuming you are in /content/QGen-Mol/code)\n",
    "target_dir = '../data/params/'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Now, run your pickle code:\n",
    "with open(os.path.join(target_dir, 'embedding_theta_params.pkl'), \"wb\") as f:\n",
    "    pickle.dump(combined_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new molecules\n",
    "from jax import random\n",
    "\n",
    "def generate_molecule_stochastic(key, props, combined_params, temperature=1.0, max_length=max_len + 2):\n",
    "    \"\"\"\n",
    "    Generates a molecule stochastically using a PRNG key for sampling.\n",
    "    \"\"\"\n",
    "    theta_params = combined_params['theta']\n",
    "    theta_prop = combined_params['theta_prop']\n",
    "    sigma_params = combined_params['sigma']\n",
    "    embedding_params = combined_params['embedding']\n",
    "\n",
    "    generated_bits = []\n",
    "    current_token = jnp.zeros((BITS_PER_TOKEN,), dtype=jnp.int32) # Start with <SOS>\n",
    "    \n",
    "    # Context tokens logic (reusing your implementation)\n",
    "    prev_token1 = SOS_token\n",
    "    prev_token2 = SOS_token\n",
    "    prev_token3 = SOS_token\n",
    "\n",
    "    for t in range(max_length):\n",
    "        # *** Critical step: Split the key for inner-loop stochasticity ***\n",
    "        key, subkey = random.split(key)\n",
    "\n",
    "        context_vector = jnp.concatenate([prev_token1, prev_token2, prev_token3])\n",
    "        theta_from_embedding = get_context_embedding(context_vector, embedding_params)\n",
    "        theta_effective = theta_params + theta_from_embedding\n",
    "\n",
    "        # The autoregressive model here uses the QNode to get probabilities\n",
    "        pred_probs, _ = autoregressive_model(current_token, props, theta_effective, theta_prop, sigma_params)\n",
    "        \n",
    "        # 1. Convert probabilities to logits (log-probabilities) for scaling\n",
    "        #    Add a small epsilon (1e-10) for numerical stability (avoids log(0))\n",
    "        logits = jnp.log(pred_probs[:VOCABULARY_SIZE] + 1e-10)\n",
    "\n",
    "        # 2. Scale logits by Temperature (logits / T)\n",
    "        tempered_logits = logits / temperature\n",
    "\n",
    "        # 3. Apply softmax to get the new, tempered probability distribution\n",
    "        tempered_probs = nn.softmax(tempered_logits)\n",
    "        \n",
    "        # 4. Sample the next index from the Tempered probability distribution\n",
    "        token_indices = jnp.arange(VOCABULARY_SIZE)\n",
    "        next_index = random.choice(\n",
    "            subkey, \n",
    "            token_indices, \n",
    "            p=tempered_probs \n",
    "        )\n",
    "\n",
    "        next_bits_str = format(int(next_index), f'0{BITS_PER_TOKEN}b')\n",
    "        next_bits = jnp.array([int(b) for b in next_bits_str], dtype=jnp.int32)\n",
    "\n",
    "        generated_bits.append(next_bits)\n",
    "\n",
    "        if next_index == eos_index:\n",
    "            break\n",
    "\n",
    "        # Update previous tokens for the next step\n",
    "        prev_token3 = prev_token2\n",
    "        prev_token2 = prev_token1\n",
    "        prev_token1 = current_token\n",
    "        current_token = next_bits\n",
    "\n",
    "    return generated_bits\n",
    "\n",
    "# Convert generated bits to SMILES\n",
    "def bits_to_smiles(generated_bits):\n",
    "    tokens = []\n",
    "    for bits in generated_bits:\n",
    "        index = int(\"\".join(map(str, bits)), 2)\n",
    "        token = alphabet[index]\n",
    "        if token == '<EOS>':\n",
    "            break\n",
    "        tokens.append(token)\n",
    "    return ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:09:44] SMILES Parse Error: syntax error while parsing: c2ccc(CC([nH]22[C@H][C@@]1(=[Li+][C@@]([C@@H][C@][S+]#)[C@]O)BrPO[O-]\\[nH]c\n",
      "[18:09:44] SMILES Parse Error: check for mistakes around position 55:\n",
      "[18:09:44] C@@]([C@@H][C@][S+]#)[C@]O)BrPO[O-]\\[nH]c\n",
      "[18:09:44] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:09:44] SMILES Parse Error: Failed parsing SMILES 'c2ccc(CC([nH]22[C@H][C@@]1(=[Li+][C@@]([C@@H][C@][S+]#)[C@]O)BrPO[O-]\\[nH]c' for input: 'c2ccc(CC([nH]22[C@H][C@@]1(=[Li+][C@@]([C@@H][C@][S+]#)[C@]O)BrPO[O-]\\[nH]c'\n",
      "[18:10:08] SMILES Parse Error: syntax error while parsing: N(CC(S#)[Cl-][C@@]oCl[Cl-]\\2C1\n",
      "[18:10:08] SMILES Parse Error: check for mistakes around position 8:\n",
      "[18:10:08] N(CC(S#)[Cl-][C@@]oCl[Cl-]\\2C1\n",
      "[18:10:08] ~~~~~~~^\n",
      "[18:10:08] SMILES Parse Error: Failed parsing SMILES 'N(CC(S#)[Cl-][C@@]oCl[Cl-]\\2C1' for input: 'N(CC(S#)[Cl-][C@@]oCl[Cl-]\\2C1'\n",
      "[18:10:55] SMILES Parse Error: syntax error while parsing: [nH]1n2N[C@@][nH]2[C@H][C@@]#CCNCC()c3cccc(S(N)(N)/ClBr\n",
      "[18:10:55] SMILES Parse Error: check for mistakes around position 36:\n",
      "[18:10:55] H]2[C@H][C@@]#CCNCC()c3cccc(S(N)(N)/ClBr\n",
      "[18:10:55] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:10:55] SMILES Parse Error: Failed parsing SMILES '[nH]1n2N[C@@][nH]2[C@H][C@@]#CCNCC()c3cccc(S(N)(N)/ClBr' for input: '[nH]1n2N[C@@][nH]2[C@H][C@@]#CCNCC()c3cccc(S(N)(N)/ClBr'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generated Molecule 4:  (Status: Valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:11:43] SMILES Parse Error: syntax error while parsing: cc12([C@@H]1(=O)=O)=[O-]#[Cl-][N+](O[C@@H][N+]oO[C@@H][O-]<SOS>S(=O)CC\n",
      "[18:11:43] SMILES Parse Error: check for mistakes around position 59:\n",
      "[18:11:43] @@H][N+]oO[C@@H][O-]<SOS>S(=O)CC\n",
      "[18:11:43] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:11:43] SMILES Parse Error: Failed parsing SMILES 'cc12([C@@H]1(=O)=O)=[O-]#[Cl-][N+](O[C@@H][N+]oO[C@@H][O-]<SOS>S(=O)CC' for input: 'cc12([C@@H]1(=O)=O)=[O-]#[Cl-][N+](O[C@@H][N+]oO[C@@H][O-]<SOS>S(=O)CC'\n",
      "[18:12:00] SMILES Parse Error: syntax error while parsing: CC1CCCI<SOS>=cIF[Li+]\n",
      "[18:12:00] SMILES Parse Error: check for mistakes around position 8:\n",
      "[18:12:00] CC1CCCI<SOS>=cIF[Li+]\n",
      "[18:12:00] ~~~~~~~^\n",
      "[18:12:00] SMILES Parse Error: Failed parsing SMILES 'CC1CCCI<SOS>=cIF[Li+]' for input: 'CC1CCCI<SOS>=cIF[Li+]'\n",
      "[18:12:08] SMILES Parse Error: unclosed ring for input: 'c1[PH][PH]n'\n",
      "[18:12:14] Explicit valence for atom # 2 O, 2, is greater than permitted\n",
      "[18:12:31] SMILES Parse Error: extra close parentheses while parsing: ns=O)CCCl23O\n",
      "[18:12:31] SMILES Parse Error: check for mistakes around position 5:\n",
      "[18:12:31] ns=O)CCCl23O\n",
      "[18:12:31] ~~~~^\n",
      "[18:12:31] SMILES Parse Error: Failed parsing SMILES 'ns=O)CCCl23O' for input: 'ns=O)CCCl23O'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generated Molecule 10:  (Status: Valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:12:49] SMILES Parse Error: syntax error while parsing: 2CN=O)c1c1(O\n",
      "[18:12:49] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:12:49] 2CN=O)c1c1(O\n",
      "[18:12:49] ^\n",
      "[18:12:49] SMILES Parse Error: Failed parsing SMILES '2CN=O)c1c1(O' for input: '2CN=O)c1c1(O'\n",
      "[18:12:55] SMILES Parse Error: extra open parentheses while parsing: N(N1\n",
      "[18:12:55] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:12:55] N(N1\n",
      "[18:12:55] ~^\n",
      "[18:12:55] SMILES Parse Error: Failed parsing SMILES 'N(N1' for input: 'N(N1'\n",
      "[18:13:32] SMILES Parse Error: extra close parentheses while parsing: cc12OC)Ccc1/[Na+][Na+][C@@][O-][C@H][N+]BrPP[C@@H]1(=O)\n",
      "[18:13:32] SMILES Parse Error: check for mistakes around position 7:\n",
      "[18:13:32] cc12OC)Ccc1/[Na+][Na+][C@@][O-][C@H][N+]B\n",
      "[18:13:32] ~~~~~~^\n",
      "[18:13:32] SMILES Parse Error: Failed parsing SMILES 'cc12OC)Ccc1/[Na+][Na+][C@@][O-][C@H][N+]BrPP[C@@H]1(=O)' for input: 'cc12OC)Ccc1/[Na+][Na+][C@@][O-][C@H][N+]BrPP[C@@H]1(=O)'\n",
      "[18:14:18] SMILES Parse Error: syntax error while parsing: N(O)cn<SOS>[C@]PCl/[nH]ccc[nH][S+]FI2(=O)=)Br((C<SOS><SOS>c[Li+]Br\n",
      "[18:14:18] SMILES Parse Error: check for mistakes around position 7:\n",
      "[18:14:18] N(O)cn<SOS>[C@]PCl/[nH]ccc[nH][S+]FI2(=O)\n",
      "[18:14:18] ~~~~~~^\n",
      "[18:14:18] SMILES Parse Error: Failed parsing SMILES 'N(O)cn<SOS>[C@]PCl/[nH]ccc[nH][S+]FI2(=O)=)Br((C<SOS><SOS>c[Li+]Br' for input: 'N(O)cn<SOS>[C@]PCl/[nH]ccc[nH][S+]FI2(=O)=)Br((C<SOS><SOS>c[Li+]Br'\n",
      "[18:15:00] SMILES Parse Error: extra close parentheses while parsing: O)=c3[PH][N+]<SOS>BrC(F)[C@][nH]<SOS>[O-][C@H]3c1Cl[Li+][C@H]O[C@@][O-]P2[nH]#\n",
      "[18:15:00] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:15:00] O)=c3[PH][N+]<SOS>BrC(F)[C@][nH]<SOS>[O-]\n",
      "[18:15:00] ~^\n",
      "[18:15:00] SMILES Parse Error: Failed parsing SMILES 'O)=c3[PH][N+]<SOS>BrC(F)[C@][nH]<SOS>[O-][C@H]3c1Cl[Li+][C@H]O[C@@][O-]P2[nH]#' for input: 'O)=c3[PH][N+]<SOS>BrC(F)[C@][nH]<SOS>[O-][C@H]3c1Cl[Li+][C@H]O[C@@][O-]P2[nH]#'\n",
      "[18:15:37] SMILES Parse Error: extra close parentheses while parsing: S(S[C@@H]O[C@@H][O-][O-]P)NNCl[Li+]O[C@@]3/[nH]O)Br[C@]Br[PH]#\n",
      "[18:15:37] SMILES Parse Error: check for mistakes around position 49:\n",
      "[18:15:37] Cl[Li+]O[C@@]3/[nH]O)Br[C@]Br[PH]#\n",
      "[18:15:37] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:15:37] SMILES Parse Error: Failed parsing SMILES 'S(S[C@@H]O[C@@H][O-][O-]P)NNCl[Li+]O[C@@]3/[nH]O)Br[C@]Br[PH]#' for input: 'S(S[C@@H]O[C@@H][O-][O-]P)NNCl[Li+]O[C@@]3/[nH]O)Br[C@]Br[PH]#'\n",
      "[18:16:06] SMILES Parse Error: extra close parentheses while parsing: cc1P[Li+]/[nH]1=O)S(3[C@][nH]1s[Na+]#\n",
      "[18:16:06] SMILES Parse Error: check for mistakes around position 18:\n",
      "[18:16:06] cc1P[Li+]/[nH]1=O)S(3[C@][nH]1s[Na+]#\n",
      "[18:16:06] ~~~~~~~~~~~~~~~~~^\n",
      "[18:16:06] SMILES Parse Error: Failed parsing SMILES 'cc1P[Li+]/[nH]1=O)S(3[C@][nH]1s[Na+]#' for input: 'cc1P[Li+]/[nH]1=O)S(3[C@][nH]1s[Na+]#'\n",
      "[18:16:52] SMILES Parse Error: syntax error while parsing: NC[Li+]N<SOS>C(<SOS>([C@H]o3S(P=[nH]cI3CC2CCCC(C(F)=C(\n",
      "[18:16:52] SMILES Parse Error: check for mistakes around position 9:\n",
      "[18:16:52] NC[Li+]N<SOS>C(<SOS>([C@H]o3S(P=[nH]cI3CC\n",
      "[18:16:52] ~~~~~~~~^\n",
      "[18:16:52] SMILES Parse Error: Failed parsing SMILES 'NC[Li+]N<SOS>C(<SOS>([C@H]o3S(P=[nH]cI3CC2CCCC(C(F)=C(' for input: 'NC[Li+]N<SOS>C(<SOS>([C@H]o3S(P=[nH]cI3CC2CCCC(C(F)=C('\n",
      "[18:17:01] SMILES Parse Error: extra open parentheses while parsing: N(c1[nH]O\n",
      "[18:17:01] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:17:01] N(c1[nH]O\n",
      "[18:17:01] ~^\n",
      "[18:17:01] SMILES Parse Error: Failed parsing SMILES 'N(c1[nH]O' for input: 'N(c1[nH]O'\n",
      "[18:17:06] SMILES Parse Error: syntax error while parsing: CN#\n",
      "[18:17:06] SMILES Parse Error: check for mistakes around position 3:\n",
      "[18:17:06] CN#\n",
      "[18:17:06] ~~^\n",
      "[18:17:06] SMILES Parse Error: Failed parsing SMILES 'CN#' for input: 'CN#'\n",
      "[18:17:44] SMILES Parse Error: syntax error while parsing: CC=O(S([O-][O-]P[Na+][Na+]=(CC(=O)CC1CCNC3Cl\n",
      "[18:17:44] SMILES Parse Error: check for mistakes around position 28:\n",
      "[18:17:44] [O-][O-]P[Na+][Na+]=(CC(=O)CC1CCNC3Cl\n",
      "[18:17:44] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:17:44] SMILES Parse Error: Failed parsing SMILES 'CC=O(S([O-][O-]P[Na+][Na+]=(CC(=O)CC1CCNC3Cl' for input: 'CC=O(S([O-][O-]P[Na+][Na+]=(CC(=O)CC1CCNC3Cl'\n",
      "[18:17:50] SMILES Parse Error: unclosed ring for input: 'N3Cl'\n",
      "[18:18:34] SMILES Parse Error: syntax error while parsing: [C@@][C@@H]([Cl-][Cl-][C@@]=F<SOS>I[Na+])oCl)CC(=O)=[Li+][S+]#c1ccc(SClP[C@@]\n",
      "[18:18:34] SMILES Parse Error: check for mistakes around position 30:\n",
      "[18:18:34] H]([Cl-][Cl-][C@@]=F<SOS>I[Na+])oCl)CC(=O\n",
      "[18:18:34] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:18:34] SMILES Parse Error: Failed parsing SMILES '[C@@][C@@H]([Cl-][Cl-][C@@]=F<SOS>I[Na+])oCl)CC(=O)=[Li+][S+]#c1ccc(SClP[C@@]' for input: '[C@@][C@@H]([Cl-][Cl-][C@@]=F<SOS>I[Na+])oCl)CC(=O)=[Li+][S+]#c1ccc(SClP[C@@]'\n",
      "[18:18:49] Explicit valence for atom # 3 Br, 3, is greater than permitted\n",
      "[18:18:59] SMILES Parse Error: extra open parentheses while parsing: N(N(CC1\n",
      "[18:18:59] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:18:59] N(N(CC1\n",
      "[18:18:59] ~^\n",
      "[18:18:59] SMILES Parse Error: extra open parentheses while parsing: N(N(CC1\n",
      "[18:18:59] SMILES Parse Error: check for mistakes around position 4:\n",
      "[18:18:59] N(N(CC1\n",
      "[18:18:59] ~~~^\n",
      "[18:18:59] SMILES Parse Error: Failed parsing SMILES 'N(N(CC1' for input: 'N(N(CC1'\n",
      "[18:19:14] SMILES Parse Error: syntax error while parsing: C[PH](S(Cl((=O)\n",
      "[18:19:14] SMILES Parse Error: check for mistakes around position 12:\n",
      "[18:19:14] C[PH](S(Cl((=O)\n",
      "[18:19:14] ~~~~~~~~~~~^\n",
      "[18:19:14] SMILES Parse Error: Failed parsing SMILES 'C[PH](S(Cl((=O)' for input: 'C[PH](S(Cl((=O)'\n",
      "[18:19:42] SMILES Parse Error: extra open parentheses while parsing: c1ccc(S=3[C@]32=NC([Li+][C@][Li+]1\n",
      "[18:19:42] SMILES Parse Error: check for mistakes around position 6:\n",
      "[18:19:42] c1ccc(S=3[C@]32=NC([Li+][C@][Li+]1\n",
      "[18:19:42] ~~~~~^\n",
      "[18:19:42] SMILES Parse Error: extra open parentheses while parsing: c1ccc(S=3[C@]32=NC([Li+][C@][Li+]1\n",
      "[18:19:42] SMILES Parse Error: check for mistakes around position 19:\n",
      "[18:19:42] c1ccc(S=3[C@]32=NC([Li+][C@][Li+]1\n",
      "[18:19:42] ~~~~~~~~~~~~~~~~~~^\n",
      "[18:19:42] SMILES Parse Error: Failed parsing SMILES 'c1ccc(S=3[C@]32=NC([Li+][C@][Li+]1' for input: 'c1ccc(S=3[C@]32=NC([Li+][C@][Li+]1'\n",
      "[18:20:26] SMILES Parse Error: extra close parentheses while parsing: cc1[N+]2)Br3[C@H]1N2CCClCCC\\3=S[O-]\\(=[C@]32)[C@@H]F)n)\n",
      "[18:20:26] SMILES Parse Error: check for mistakes around position 9:\n",
      "[18:20:26] cc1[N+]2)Br3[C@H]1N2CCClCCC\\3=S[O-]\\(=[C@\n",
      "[18:20:26] ~~~~~~~~^\n",
      "[18:20:26] SMILES Parse Error: Failed parsing SMILES 'cc1[N+]2)Br3[C@H]1N2CCClCCC\\3=S[O-]\\(=[C@]32)[C@@H]F)n)' for input: 'cc1[N+]2)Br3[C@H]1N2CCClCCC\\3=S[O-]\\(=[C@]32)[C@@H]F)n)'\n",
      "[18:20:34] SMILES Parse Error: unclosed ring for input: 'C23sCl'\n",
      "[18:20:41] SMILES Parse Error: unclosed ring for input: 'CCcc1'\n",
      "[18:20:55] SMILES Parse Error: unclosed ring for input: 'Brcc1ns=[nH][nH]s'\n",
      "[18:21:40] SMILES Parse Error: extra close parentheses while parsing: cc1=O)c1cccc2cccc2)C#NC(Snn#2(O[Li+]3[nH]<SOS>\n",
      "[18:21:40] SMILES Parse Error: check for mistakes around position 6:\n",
      "[18:21:40] cc1=O)c1cccc2cccc2)C#NC(Snn#2(O[Li+]3[nH]\n",
      "[18:21:40] ~~~~~^\n",
      "[18:21:40] SMILES Parse Error: Failed parsing SMILES 'cc1=O)c1cccc2cccc2)C#NC(Snn#2(O[Li+]3[nH]<SOS>' for input: 'cc1=O)c1cccc2cccc2)C#NC(Snn#2(O[Li+]3[nH]<SOS>'\n",
      "[18:22:26] SMILES Parse Error: syntax error while parsing: CCCC(=O)=NS(O<SOS>N2CC(I[C@H][C@@]=[C@@H][C@@][N+]c23<SOS>C1[C@H][PH][C@@]\n",
      "[18:22:26] SMILES Parse Error: check for mistakes around position 14:\n",
      "[18:22:26] CCCC(=O)=NS(O<SOS>N2CC(I[C@H][C@@]=[C@@H]\n",
      "[18:22:26] ~~~~~~~~~~~~~^\n",
      "[18:22:26] SMILES Parse Error: Failed parsing SMILES 'CCCC(=O)=NS(O<SOS>N2CC(I[C@H][C@@]=[C@@H][C@@][N+]c23<SOS>C1[C@H][PH][C@@]' for input: 'CCCC(=O)=NS(O<SOS>N2CC(I[C@H][C@@]=[C@@H][C@@][N+]c23<SOS>C1[C@H][PH][C@@]'\n",
      "[18:23:08] SMILES Parse Error: extra close parentheses while parsing: NI[nH]1c32c(=O)O)c<SOS>Cl31[Na+][Li+]c2FOClC1\n",
      "[18:23:08] SMILES Parse Error: check for mistakes around position 17:\n",
      "[18:23:08] NI[nH]1c32c(=O)O)c<SOS>Cl31[Na+][Li+]c2FO\n",
      "[18:23:08] ~~~~~~~~~~~~~~~~^\n",
      "[18:23:08] SMILES Parse Error: Failed parsing SMILES 'NI[nH]1c32c(=O)O)c<SOS>Cl31[Na+][Li+]c2FOClC1' for input: 'NI[nH]1c32c(=O)O)c<SOS>Cl31[Na+][Li+]c2FOClC1'\n",
      "[18:23:14] SMILES Parse Error: syntax error while parsing: =OCl\n",
      "[18:23:14] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:23:14] =OCl\n",
      "[18:23:14] ^\n",
      "[18:23:14] SMILES Parse Error: Failed parsing SMILES '=OCl' for input: '=OCl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generated Molecule 36:  (Status: Valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:23:41] SMILES Parse Error: extra close parentheses while parsing: C)=#1CCC(C(C()cc1n\n",
      "[18:23:41] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:23:41] C)=#1CCC(C(C()cc1n\n",
      "[18:23:41] ~^\n",
      "[18:23:41] SMILES Parse Error: Failed parsing SMILES 'C)=#1CCC(C(C()cc1n' for input: 'C)=#1CCC(C(C()cc1n'\n",
      "[18:23:58] Can't kekulize mol.  Unkekulized atoms: 1 4 5\n",
      "[18:24:44] SMILES Parse Error: extra close parentheses while parsing: N)=O1C3Cc1c[C@@H]\\[Na+]n([Na+][nH]cc2c1CCN)Cc1nnF[C@@H][Cl-]\n",
      "[18:24:44] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:24:44] N)=O1C3Cc1c[C@@H]\\[Na+]n([Na+][nH]cc2c1CC\n",
      "[18:24:44] ~^\n",
      "[18:24:44] SMILES Parse Error: Failed parsing SMILES 'N)=O1C3Cc1c[C@@H]\\[Na+]n([Na+][nH]cc2c1CCN)Cc1nnF[C@@H][Cl-]' for input: 'N)=O1C3Cc1c[C@@H]\\[Na+]n([Na+][nH]cc2c1CCN)Cc1nnF[C@@H][Cl-]'\n",
      "[18:25:18] SMILES Parse Error: syntax error while parsing: N[Cl-][C@H][Cl-]<SOS>c1[C@]C1=CCCC1[C@H][O-][PH][O-][Cl-][C@@]1C1\n",
      "[18:25:18] SMILES Parse Error: check for mistakes around position 17:\n",
      "[18:25:18] N[Cl-][C@H][Cl-]<SOS>c1[C@]C1=CCCC1[C@H][\n",
      "[18:25:18] ~~~~~~~~~~~~~~~~^\n",
      "[18:25:18] SMILES Parse Error: Failed parsing SMILES 'N[Cl-][C@H][Cl-]<SOS>c1[C@]C1=CCCC1[C@H][O-][PH][O-][Cl-][C@@]1C1' for input: 'N[Cl-][C@H][Cl-]<SOS>c1[C@]C1=CCCC1[C@H][O-][PH][O-][Cl-][C@@]1C1'\n",
      "[18:25:35] SMILES Parse Error: syntax error while parsing: =ONCS()=CCC1\n",
      "[18:25:35] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:25:35] =ONCS()=CCC1\n",
      "[18:25:35] ^\n",
      "[18:25:35] SMILES Parse Error: Failed parsing SMILES '=ONCS()=CCC1' for input: '=ONCS()=CCC1'\n",
      "[18:26:22] SMILES Parse Error: syntax error while parsing: C1=)ccc2/[Cl-]I2c[O-](=OI2ccccccc\\[nH]33noc2c\n",
      "[18:26:22] SMILES Parse Error: check for mistakes around position 4:\n",
      "[18:26:22] C1=)ccc2/[Cl-]I2c[O-](=OI2ccccccc\\[nH]33n\n",
      "[18:26:22] ~~~^\n",
      "[18:26:22] SMILES Parse Error: Failed parsing SMILES 'C1=)ccc2/[Cl-]I2c[O-](=OI2ccccccc\\[nH]33noc2c' for input: 'C1=)ccc2/[Cl-]I2c[O-](=OI2ccccccc\\[nH]33noc2c'\n",
      "[18:26:35] Can't kekulize mol.  Unkekulized atoms: 1\n",
      "[18:26:54] SMILES Parse Error: extra open parentheses while parsing: C2=C2C(=C1=SP[O-]\n",
      "[18:26:54] SMILES Parse Error: check for mistakes around position 7:\n",
      "[18:26:54] C2=C2C(=C1=SP[O-]\n",
      "[18:26:54] ~~~~~~^\n",
      "[18:26:54] SMILES Parse Error: Failed parsing SMILES 'C2=C2C(=C1=SP[O-]' for input: 'C2=C2C(=C1=SP[O-]'\n",
      "[18:27:39] SMILES Parse Error: syntax error while parsing: c1no(P[C@H]1o=P[Li+]3/=[Li+]2cccc\\\\[C@H]1cc1[N+][PH][PH][PH]Br3C\n",
      "[18:27:39] SMILES Parse Error: check for mistakes around position 23:\n",
      "[18:27:39] no(P[C@H]1o=P[Li+]3/=[Li+]2cccc\\\\[C@H]1cc\n",
      "[18:27:39] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:27:39] SMILES Parse Error: Failed parsing SMILES 'c1no(P[C@H]1o=P[Li+]3/=[Li+]2cccc\\\\[C@H]1cc1[N+][PH][PH][PH]Br3C' for input: 'c1no(P[C@H]1o=P[Li+]3/=[Li+]2cccc\\\\[C@H]1cc1[N+][PH][PH][PH]Br3C'\n",
      "[18:27:54] SMILES Parse Error: extra close parentheses while parsing: NC[C@@H]\\3[C@@H])(O(Cl\n",
      "[18:27:54] SMILES Parse Error: check for mistakes around position 17:\n",
      "[18:27:54] NC[C@@H]\\3[C@@H])(O(Cl\n",
      "[18:27:54] ~~~~~~~~~~~~~~~~^\n",
      "[18:27:54] SMILES Parse Error: Failed parsing SMILES 'NC[C@@H]\\3[C@@H])(O(Cl' for input: 'NC[C@@H]\\3[C@@H])(O(Cl'\n",
      "[18:28:34] SMILES Parse Error: syntax error while parsing: cc[C@@][Na+]C1=cn<SOS>CNCN(CCl)[PH][C@@][C@@]<SOS>Br[C@]3[C@@]#\n",
      "[18:28:34] SMILES Parse Error: check for mistakes around position 18:\n",
      "[18:28:34] cc[C@@][Na+]C1=cn<SOS>CNCN(CCl)[PH][C@@][\n",
      "[18:28:34] ~~~~~~~~~~~~~~~~~^\n",
      "[18:28:34] SMILES Parse Error: Failed parsing SMILES 'cc[C@@][Na+]C1=cn<SOS>CNCN(CCl)[PH][C@@][C@@]<SOS>Br[C@]3[C@@]#' for input: 'cc[C@@][Na+]C1=cn<SOS>CNCN(CCl)[PH][C@@][C@@]<SOS>Br[C@]3[C@@]#'\n",
      "[18:29:19] SMILES Parse Error: extra close parentheses while parsing: NCN)[Cl-]/(=Sc1nn2[C@@H][N+][C@@H]ISn[C@][nH]1Cc1ccc(S[O-][PH][PH]s\n",
      "[18:29:19] SMILES Parse Error: check for mistakes around position 4:\n",
      "[18:29:19] NCN)[Cl-]/(=Sc1nn2[C@@H][N+][C@@H]ISn[C@]\n",
      "[18:29:19] ~~~^\n",
      "[18:29:19] SMILES Parse Error: Failed parsing SMILES 'NCN)[Cl-]/(=Sc1nn2[C@@H][N+][C@@H]ISn[C@][nH]1Cc1ccc(S[O-][PH][PH]s' for input: 'NCN)[Cl-]/(=Sc1nn2[C@@H][N+][C@@H]ISn[C@][nH]1Cc1ccc(S[O-][PH][PH]s'\n",
      "[18:29:59] SMILES Parse Error: extra open parentheses while parsing: [nH]1c1CP[C@@]oc(Br[C@@H][C@@][S+][C@@H][Cl-][C@@]=O=CC[Na+]c3NCCP#o\n",
      "[18:29:59] SMILES Parse Error: check for mistakes around position 17:\n",
      "[18:29:59] [nH]1c1CP[C@@]oc(Br[C@@H][C@@][S+][C@@H][\n",
      "[18:29:59] ~~~~~~~~~~~~~~~~^\n",
      "[18:29:59] SMILES Parse Error: Failed parsing SMILES '[nH]1c1CP[C@@]oc(Br[C@@H][C@@][S+][C@@H][Cl-][C@@]=O=CC[Na+]c3NCCP#o' for input: '[nH]1c1CP[C@@]oc(Br[C@@H][C@@][S+][C@@H][Cl-][C@@]=O=CC[Na+]c3NCCP#o'\n",
      "[18:30:14] SMILES Parse Error: extra open parentheses while parsing: Cl3c(CNc[Li+][C@@]Br\n",
      "[18:30:14] SMILES Parse Error: check for mistakes around position 5:\n",
      "[18:30:14] Cl3c(CNc[Li+][C@@]Br\n",
      "[18:30:14] ~~~~^\n",
      "[18:30:14] SMILES Parse Error: Failed parsing SMILES 'Cl3c(CNc[Li+][C@@]Br' for input: 'Cl3c(CNc[Li+][C@@]Br'\n",
      "[18:31:00] SMILES Parse Error: syntax error while parsing: CC(=O[Na+][C@H][Cl-][O-]=O\\\\[S+]2<SOS>S)CI[C@H][O-](N[O-][nH]#FF[C@](O(=O\n",
      "[18:31:00] SMILES Parse Error: check for mistakes around position 34:\n",
      "[18:31:00] H][Cl-][O-]=O\\\\[S+]2<SOS>S)CI[C@H][O-](N[\n",
      "[18:31:00] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:31:00] SMILES Parse Error: Failed parsing SMILES 'CC(=O[Na+][C@H][Cl-][O-]=O\\\\[S+]2<SOS>S)CI[C@H][O-](N[O-][nH]#FF[C@](O(=O' for input: 'CC(=O[Na+][C@H][Cl-][O-]=O\\\\[S+]2<SOS>S)CI[C@H][O-](N[O-][nH]#FF[C@](O(=O'\n",
      "[18:31:35] SMILES Parse Error: extra close parentheses while parsing: C)[S+][Li+]F[Li+]3[PH]s[C@@H][C@][N+]Br(<SOS>F=[C@@H][C@H]P[C@]3BrN1\n",
      "[18:31:35] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:31:35] C)[S+][Li+]F[Li+]3[PH]s[C@@H][C@][N+]Br(<\n",
      "[18:31:35] ~^\n",
      "[18:31:35] SMILES Parse Error: Failed parsing SMILES 'C)[S+][Li+]F[Li+]3[PH]s[C@@H][C@][N+]Br(<SOS>F=[C@@H][C@H]P[C@]3BrN1' for input: 'C)[S+][Li+]F[Li+]3[PH]s[C@@H][C@][N+]Br(<SOS>F=[C@@H][C@H]P[C@]3BrN1'\n",
      "[18:32:03] SMILES Parse Error: extra close parentheses while parsing: c[N+]I[C@H])Br)C3[C@]<SOS>CCCC2)cc2Cl\n",
      "[18:32:03] SMILES Parse Error: check for mistakes around position 12:\n",
      "[18:32:03] c[N+]I[C@H])Br)C3[C@]<SOS>CCCC2)cc2Cl\n",
      "[18:32:03] ~~~~~~~~~~~^\n",
      "[18:32:03] SMILES Parse Error: Failed parsing SMILES 'c[N+]I[C@H])Br)C3[C@]<SOS>CCCC2)cc2Cl' for input: 'c[N+]I[C@H])Br)C3[C@]<SOS>CCCC2)cc2Cl'\n",
      "[18:32:32] SMILES Parse Error: syntax error while parsing: N1COn21sClscI<SOS>C3=[C@H][Li+]/BrNCl\n",
      "[18:32:32] SMILES Parse Error: check for mistakes around position 14:\n",
      "[18:32:32] N1COn21sClscI<SOS>C3=[C@H][Li+]/BrNCl\n",
      "[18:32:32] ~~~~~~~~~~~~~^\n",
      "[18:32:32] SMILES Parse Error: Failed parsing SMILES 'N1COn21sClscI<SOS>C3=[C@H][Li+]/BrNCl' for input: 'N1COn21sClscI<SOS>C3=[C@H][Li+]/BrNCl'\n",
      "[18:33:09] SMILES Parse Error: extra close parentheses while parsing: cc1c[C@@][C@H])[Li+][Li+][nH][S+]<SOS>Cl[Na+][nH]\\[C@@H](C[Cl-][C@@]P[nH][O-][C@H]1Cl\n",
      "[18:33:09] SMILES Parse Error: check for mistakes around position 15:\n",
      "[18:33:09] cc1c[C@@][C@H])[Li+][Li+][nH][S+]<SOS>Cl[\n",
      "[18:33:09] ~~~~~~~~~~~~~~^\n",
      "[18:33:09] SMILES Parse Error: Failed parsing SMILES 'cc1c[C@@][C@H])[Li+][Li+][nH][S+]<SOS>Cl[Na+][nH]\\[C@@H](C[Cl-][C@@]P[nH][O-][C@H]1Cl' for input: 'cc1c[C@@][C@H])[Li+][Li+][nH][S+]<SOS>Cl[Na+][nH]\\[C@@H](C[Cl-][C@@]P[nH][O-][C@H]1Cl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generated Molecule 56:  (Status: Valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:33:54] SMILES Parse Error: syntax error while parsing: (=C2[nH]ccc[C@@][PH][C@@]o(=C3scc2)nn1CCCCCC2)\n",
      "[18:33:54] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:33:54] (=C2[nH]ccc[C@@][PH][C@@]o(=C3scc2)nn1CCC\n",
      "[18:33:54] ^\n",
      "[18:33:54] SMILES Parse Error: Failed parsing SMILES '(=C2[nH]ccc[C@@][PH][C@@]o(=C3scc2)nn1CCCCCC2)' for input: '(=C2[nH]ccc[C@@][PH][C@@]o(=C3scc2)nn1CCCCCC2)'\n",
      "[18:34:12] SMILES Parse Error: unclosed ring for input: 'c1ccc(=O)/ss'\n",
      "[18:34:47] SMILES Parse Error: extra close parentheses while parsing: N1cc1F1[Li+][PH]nn=Cl)F[Cl-]P\\[Na+]/CNC#Cl\n",
      "[18:34:47] SMILES Parse Error: check for mistakes around position 22:\n",
      "[18:34:47] 1cc1F1[Li+][PH]nn=Cl)F[Cl-]P\\[Na+]/CNC#Cl\n",
      "[18:34:47] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:34:47] SMILES Parse Error: Failed parsing SMILES 'N1cc1F1[Li+][PH]nn=Cl)F[Cl-]P\\[Na+]/CNC#Cl' for input: 'N1cc1F1[Li+][PH]nn=Cl)F[Cl-]P\\[Na+]/CNC#Cl'\n",
      "[18:34:53] SMILES Parse Error: extra close parentheses while parsing: N)\n",
      "[18:34:53] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:34:53] N)\n",
      "[18:34:53] ~^\n",
      "[18:34:53] SMILES Parse Error: Failed parsing SMILES 'N)' for input: 'N)'\n",
      "[18:35:42] SMILES Parse Error: syntax error while parsing: N(O[C@@H][O-][O-]CIc1ccc(SO1CClClCl)[Cl-]I<SOS>C1=[Li+]3ccccc\n",
      "[18:35:42] SMILES Parse Error: check for mistakes around position 43:\n",
      "[18:35:42] cc(SO1CClClCl)[Cl-]I<SOS>C1=[Li+]3ccccc\n",
      "[18:35:42] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:35:42] SMILES Parse Error: Failed parsing SMILES 'N(O[C@@H][O-][O-]CIc1ccc(SO1CClClCl)[Cl-]I<SOS>C1=[Li+]3ccccc' for input: 'N(O[C@@H][O-][O-]CIc1ccc(SO1CClClCl)[Cl-]I<SOS>C1=[Li+]3ccccc'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generated Molecule 62:  (Status: Valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:35:56] SMILES Parse Error: extra open parentheses while parsing: c1nc([O-][N+]1\n",
      "[18:35:56] SMILES Parse Error: check for mistakes around position 5:\n",
      "[18:35:56] c1nc([O-][N+]1\n",
      "[18:35:56] ~~~~^\n",
      "[18:35:56] SMILES Parse Error: Failed parsing SMILES 'c1nc([O-][N+]1' for input: 'c1nc([O-][N+]1'\n",
      "[18:36:04] SMILES Parse Error: extra open parentheses while parsing: N(CC2\n",
      "[18:36:04] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:36:04] N(CC2\n",
      "[18:36:04] ~^\n",
      "[18:36:04] SMILES Parse Error: Failed parsing SMILES 'N(CC2' for input: 'N(CC2'\n",
      "[18:36:59] SMILES Parse Error: syntax error while parsing: CC(O(FCF)c1ccc2C(=N<SOS>[O-][Na+]I[C@H][C@@][PH][PH][O-][C@H][PH]c1ccc\n",
      "[18:36:59] SMILES Parse Error: check for mistakes around position 20:\n",
      "[18:36:59] CC(O(FCF)c1ccc2C(=N<SOS>[O-][Na+]I[C@H][C\n",
      "[18:36:59] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:36:59] SMILES Parse Error: Failed parsing SMILES 'CC(O(FCF)c1ccc2C(=N<SOS>[O-][Na+]I[C@H][C@@][PH][PH][O-][C@H][PH]c1ccc' for input: 'CC(O(FCF)c1ccc2C(=N<SOS>[O-][Na+]I[C@H][C@@][PH][PH][O-][C@H][PH]c1ccc'\n",
      "[18:37:18] SMILES Parse Error: syntax error while parsing: (=O([C@@H][S+][S+][N+][Na+]n1Cl\n",
      "[18:37:18] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:37:18] (=O([C@@H][S+][S+][N+][Na+]n1Cl\n",
      "[18:37:18] ^\n",
      "[18:37:18] SMILES Parse Error: Failed parsing SMILES '(=O([C@@H][S+][S+][N+][Na+]n1Cl' for input: '(=O([C@@H][S+][S+][N+][Na+]n1Cl'\n",
      "[18:38:03] SMILES Parse Error: syntax error while parsing: 2(S(=O)=O)FO1C2(O[Na+]O2(O[C@H][Li+][S+]I(=O)cnFCC\n",
      "[18:38:03] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:38:03] 2(S(=O)=O)FO1C2(O[Na+]O2(O[C@H][Li+][S+]I\n",
      "[18:38:03] ^\n",
      "[18:38:03] SMILES Parse Error: Failed parsing SMILES '2(S(=O)=O)FO1C2(O[Na+]O2(O[C@H][Li+][S+]I(=O)cnFCC' for input: '2(S(=O)=O)FO1C2(O[Na+]O2(O[C@H][Li+][S+]I(=O)cnFCC'\n",
      "[18:38:12] SMILES Parse Error: extra open parentheses while parsing: N([C@@H]\\\\Cl\n",
      "[18:38:12] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:38:12] N([C@@H]\\\\Cl\n",
      "[18:38:12] ~^\n",
      "[18:38:12] SMILES Parse Error: Failed parsing SMILES 'N([C@@H]\\\\Cl' for input: 'N([C@@H]\\\\Cl'\n",
      "[18:38:53] SMILES Parse Error: syntax error while parsing: N(CC3<SOS>c1nccc\\1C(=C2[S+][Li+])CC)CCCl<SOS>\n",
      "[18:38:53] SMILES Parse Error: check for mistakes around position 6:\n",
      "[18:38:53] N(CC3<SOS>c1nccc\\1C(=C2[S+][Li+])CC)CCCl<\n",
      "[18:38:53] ~~~~~^\n",
      "[18:38:53] SMILES Parse Error: Failed parsing SMILES 'N(CC3<SOS>c1nccc\\1C(=C2[S+][Li+])CC)CCCl<SOS>' for input: 'N(CC3<SOS>c1nccc\\1C(=C2[S+][Li+])CC)CCCl<SOS>'\n",
      "[18:38:59] SMILES Parse Error: syntax error while parsing: CCC#\n",
      "[18:38:59] SMILES Parse Error: check for mistakes around position 4:\n",
      "[18:38:59] CCC#\n",
      "[18:38:59] ~~~^\n",
      "[18:38:59] SMILES Parse Error: Failed parsing SMILES 'CCC#' for input: 'CCC#'\n",
      "[18:39:07] SMILES Parse Error: unclosed ring for input: 'cc1Br'\n",
      "[18:39:26] SMILES Parse Error: extra close parentheses while parsing: NCS(=O)=O)c1\n",
      "[18:39:26] SMILES Parse Error: check for mistakes around position 10:\n",
      "[18:39:26] NCS(=O)=O)c1\n",
      "[18:39:26] ~~~~~~~~~^\n",
      "[18:39:26] SMILES Parse Error: Failed parsing SMILES 'NCS(=O)=O)c1' for input: 'NCS(=O)=O)c1'\n",
      "[18:40:04] SMILES Parse Error: extra close parentheses while parsing: Cc[N+]1C2(N)=O)cc2cccc([Li+]3coCl\n",
      "[18:40:04] SMILES Parse Error: check for mistakes around position 15:\n",
      "[18:40:04] Cc[N+]1C2(N)=O)cc2cccc([Li+]3coCl\n",
      "[18:40:04] ~~~~~~~~~~~~~~^\n",
      "[18:40:04] SMILES Parse Error: Failed parsing SMILES 'Cc[N+]1C2(N)=O)cc2cccc([Li+]3coCl' for input: 'Cc[N+]1C2(N)=O)cc2cccc([Li+]3coCl'\n",
      "[18:40:48] SMILES Parse Error: extra open parentheses while parsing: c[C@@][O-][PH][O-]C([C@@H][C@@]/S[C@@H]\\2N(N3[nH]1=Occ1F[PH]#cc1n\n",
      "[18:40:48] SMILES Parse Error: check for mistakes around position 20:\n",
      "[18:40:48] c[C@@][O-][PH][O-]C([C@@H][C@@]/S[C@@H]\\2\n",
      "[18:40:48] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:40:48] SMILES Parse Error: extra open parentheses while parsing: c[C@@][O-][PH][O-]C([C@@H][C@@]/S[C@@H]\\2N(N3[nH]1=Occ1F[PH]#cc1n\n",
      "[18:40:48] SMILES Parse Error: check for mistakes around position 43:\n",
      "[18:40:48] @@H][C@@]/S[C@@H]\\2N(N3[nH]1=Occ1F[PH]#cc\n",
      "[18:40:48] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:40:48] SMILES Parse Error: Failed parsing SMILES 'c[C@@][O-][PH][O-]C([C@@H][C@@]/S[C@@H]\\2N(N3[nH]1=Occ1F[PH]#cc1n' for input: 'c[C@@][O-][PH][O-]C([C@@H][C@@]/S[C@@H]\\2N(N3[nH]1=Occ1F[PH]#cc1n'\n",
      "[18:41:11] SMILES Parse Error: syntax error while parsing: )C(C[S+]1FO)=NCC[N+]#Cl\n",
      "[18:41:11] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:41:11] )C(C[S+]1FO)=NCC[N+]#Cl\n",
      "[18:41:11] ^\n",
      "[18:41:11] SMILES Parse Error: Failed parsing SMILES ')C(C[S+]1FO)=NCC[N+]#Cl' for input: ')C(C[S+]1FO)=NCC[N+]#Cl'\n",
      "[18:41:32] SMILES Parse Error: extra open parentheses while parsing: c1Clsc(=[Cl-][Li+]IP\\[C@@][C@@]2\n",
      "[18:41:32] SMILES Parse Error: check for mistakes around position 7:\n",
      "[18:41:32] c1Clsc(=[Cl-][Li+]IP\\[C@@][C@@]2\n",
      "[18:41:32] ~~~~~~^\n",
      "[18:41:32] SMILES Parse Error: Failed parsing SMILES 'c1Clsc(=[Cl-][Li+]IP\\[C@@][C@@]2' for input: 'c1Clsc(=[Cl-][Li+]IP\\[C@@][C@@]2'\n",
      "[18:42:18] SMILES Parse Error: extra close parentheses while parsing: CO)\\\\\\[O-]\\[O-]\\(OCCno==)<SOS>(S(SP[Na+]P[N+]Br/[N+][C@@H][Cl-]c1\n",
      "[18:42:18] SMILES Parse Error: check for mistakes around position 3:\n",
      "[18:42:18] CO)\\\\\\[O-]\\[O-]\\(OCCno==)<SOS>(S(SP[Na+]P\n",
      "[18:42:18] ~~^\n",
      "[18:42:18] SMILES Parse Error: Failed parsing SMILES 'CO)\\\\\\[O-]\\[O-]\\(OCCno==)<SOS>(S(SP[Na+]P[N+]Br/[N+][C@@H][Cl-]c1' for input: 'CO)\\\\\\[O-]\\[O-]\\(OCCno==)<SOS>(S(SP[Na+]P[N+]Br/[N+][C@@H][Cl-]c1'\n",
      "[18:42:21] SMILES Parse Error: syntax error while parsing: 2\n",
      "[18:42:21] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:42:21] 2\n",
      "[18:42:21] ^\n",
      "[18:42:21] SMILES Parse Error: Failed parsing SMILES '2' for input: '2'\n",
      "[18:42:51] SMILES Parse Error: syntax error while parsing: [C@@H]\\3C2[nH]cc[C@H]IN(=/==O)=OPs[Li+]\n",
      "[18:42:51] SMILES Parse Error: check for mistakes around position 26:\n",
      "[18:42:51] ]\\3C2[nH]cc[C@H]IN(=/==O)=OPs[Li+]\n",
      "[18:42:51] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:42:51] SMILES Parse Error: Failed parsing SMILES '[C@@H]\\3C2[nH]cc[C@H]IN(=/==O)=OPs[Li+]' for input: '[C@@H]\\3C2[nH]cc[C@H]IN(=/==O)=OPs[Li+]'\n",
      "[18:43:28] SMILES Parse Error: extra close parentheses while parsing: c1ccc(S2N)cc1NCN)[Cl-](=3CC23oFCl\n",
      "[18:43:28] SMILES Parse Error: check for mistakes around position 17:\n",
      "[18:43:28] c1ccc(S2N)cc1NCN)[Cl-](=3CC23oFCl\n",
      "[18:43:28] ~~~~~~~~~~~~~~~~^\n",
      "[18:43:28] SMILES Parse Error: Failed parsing SMILES 'c1ccc(S2N)cc1NCN)[Cl-](=3CC23oFCl' for input: 'c1ccc(S2N)cc1NCN)[Cl-](=3CC23oFCl'\n",
      "[18:44:13] SMILES Parse Error: syntax error while parsing: c1ccc([C@@H][nH]I[C@H][C@@]#CCl<SOS>I[Na+][O-][O-](=OC)[PH][N+][PH]nc[nH]/O[PH][PH]n\n",
      "[18:44:13] SMILES Parse Error: check for mistakes around position 32:\n",
      "[18:44:13] ][nH]I[C@H][C@@]#CCl<SOS>I[Na+][O-][O-](=\n",
      "[18:44:13] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:44:13] SMILES Parse Error: Failed parsing SMILES 'c1ccc([C@@H][nH]I[C@H][C@@]#CCl<SOS>I[Na+][O-][O-](=OC)[PH][N+][PH]nc[nH]/O[PH][PH]n' for input: 'c1ccc([C@@H][nH]I[C@H][C@@]#CCl<SOS>I[Na+][O-][O-](=OC)[PH][N+][PH]nc[nH]/O[PH][PH]n'\n",
      "[18:44:58] SMILES Parse Error: extra close parentheses while parsing: N[N+][Na+])[Li+][nH]cc\\1cc2Cl[Na+](3CN1Cc1cccccc2o33[C@]P\n",
      "[18:44:58] SMILES Parse Error: check for mistakes around position 11:\n",
      "[18:44:58] N[N+][Na+])[Li+][nH]cc\\1cc2Cl[Na+](3CN1Cc\n",
      "[18:44:58] ~~~~~~~~~~^\n",
      "[18:44:58] SMILES Parse Error: Failed parsing SMILES 'N[N+][Na+])[Li+][nH]cc\\1cc2Cl[Na+](3CN1Cc1cccccc2o33[C@]P' for input: 'N[N+][Na+])[Li+][nH]cc\\1cc2Cl[Na+](3CN1Cc1cccccc2o33[C@]P'\n",
      "[18:45:45] SMILES Parse Error: extra close parentheses while parsing: c1cccc1Broccc2S/P2)[nH]3[C@H])[nH]1(C([C@@H]\\[C@@]/=<SOS>so\n",
      "[18:45:45] SMILES Parse Error: check for mistakes around position 19:\n",
      "[18:45:45] c1cccc1Broccc2S/P2)[nH]3[C@H])[nH]1(C([C@\n",
      "[18:45:45] ~~~~~~~~~~~~~~~~~~^\n",
      "[18:45:45] SMILES Parse Error: Failed parsing SMILES 'c1cccc1Broccc2S/P2)[nH]3[C@H])[nH]1(C([C@@H]\\[C@@]/=<SOS>so' for input: 'c1cccc1Broccc2S/P2)[nH]3[C@H])[nH]1(C([C@@H]\\[C@@]/=<SOS>so'\n",
      "[18:46:30] SMILES Parse Error: syntax error while parsing: N23[nH]c\\[Cl-]([C@]3[Cl-]Cl<SOS>[N+][N+]CloCl)ccc3c[N+](F[C@@H][O-][Na+](C(S(\n",
      "[18:46:30] SMILES Parse Error: check for mistakes around position 28:\n",
      "[18:46:30] c\\[Cl-]([C@]3[Cl-]Cl<SOS>[N+][N+]CloCl)cc\n",
      "[18:46:30] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:46:30] SMILES Parse Error: Failed parsing SMILES 'N23[nH]c\\[Cl-]([C@]3[Cl-]Cl<SOS>[N+][N+]CloCl)ccc3c[N+](F[C@@H][O-][Na+](C(S(' for input: 'N23[nH]c\\[Cl-]([C@]3[Cl-]Cl<SOS>[N+][N+]CloCl)ccc3c[N+](F[C@@H][O-][Na+](C(S('\n",
      "[18:47:15] SMILES Parse Error: syntax error while parsing: N(C(=O)c1nnN1[C@H]/=c1cccc2N1CCBrc[C@]OBr[C@H]3n\n",
      "[18:47:15] SMILES Parse Error: check for mistakes around position 20:\n",
      "[18:47:15] N(C(=O)c1nnN1[C@H]/=c1cccc2N1CCBrc[C@]OBr\n",
      "[18:47:15] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:47:15] SMILES Parse Error: Failed parsing SMILES 'N(C(=O)c1nnN1[C@H]/=c1cccc2N1CCBrc[C@]OBr[C@H]3n' for input: 'N(C(=O)c1nnN1[C@H]/=c1cccc2N1CCBrc[C@]OBr[C@H]3n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generated Molecule 86:  (Status: Valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:48:01] SMILES Parse Error: syntax error while parsing: C1[C@@][PH]#[nH]ccc2sI/)=2[Cl-])=O)<SOS>CC)cc1[Na+]cc2ccc\n",
      "[18:48:01] SMILES Parse Error: check for mistakes around position 24:\n",
      "[18:48:01] C@@][PH]#[nH]ccc2sI/)=2[Cl-])=O)<SOS>CC)c\n",
      "[18:48:01] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:48:01] SMILES Parse Error: Failed parsing SMILES 'C1[C@@][PH]#[nH]ccc2sI/)=2[Cl-])=O)<SOS>CC)cc1[Na+]cc2ccc' for input: 'C1[C@@][PH]#[nH]ccc2sI/)=2[Cl-])=O)<SOS>CC)cc1[Na+]cc2ccc'\n",
      "[18:48:41] SMILES Parse Error: syntax error while parsing: cc1ccc(S[O-]c1ccc(S[C@H][S+]\\[nH]<SOS>N\\[Na+]cc\\2c#\n",
      "[18:48:41] SMILES Parse Error: check for mistakes around position 34:\n",
      "[18:48:41] 1ccc(S[C@H][S+]\\[nH]<SOS>N\\[Na+]cc\\2c#\n",
      "[18:48:41] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:48:41] SMILES Parse Error: Failed parsing SMILES 'cc1ccc(S[O-]c1ccc(S[C@H][S+]\\[nH]<SOS>N\\[Na+]cc\\2c#' for input: 'cc1ccc(S[O-]c1ccc(S[C@H][S+]\\[nH]<SOS>N\\[Na+]cc\\2c#'\n",
      "[18:49:11] SMILES Parse Error: extra close parentheses while parsing: c1=O)cOO)o[C@H])[Li+][C@]3[nH]cc[S+]P2(\n",
      "[18:49:11] SMILES Parse Error: check for mistakes around position 5:\n",
      "[18:49:11] c1=O)cOO)o[C@H])[Li+][C@]3[nH]cc[S+]P2(\n",
      "[18:49:11] ~~~~^\n",
      "[18:49:11] SMILES Parse Error: Failed parsing SMILES 'c1=O)cOO)o[C@H])[Li+][C@]3[nH]cc[S+]P2(' for input: 'c1=O)cOO)o[C@H])[Li+][C@]3[nH]cc[S+]P2('\n",
      "[18:49:56] SMILES Parse Error: extra close parentheses while parsing: OsCl3C)Br3[nH]3[nH]cc2)=[O-]/C((=O)S(=OS(C32=[Cl-]\n",
      "[18:49:56] SMILES Parse Error: check for mistakes around position 7:\n",
      "[18:49:56] OsCl3C)Br3[nH]3[nH]cc2)=[O-]/C((=O)S(=OS(\n",
      "[18:49:56] ~~~~~~^\n",
      "[18:49:56] SMILES Parse Error: Failed parsing SMILES 'OsCl3C)Br3[nH]3[nH]cc2)=[O-]/C((=O)S(=OS(C32=[Cl-]' for input: 'OsCl3C)Br3[nH]3[nH]cc2)=[O-]/C((=O)S(=OS(C32=[Cl-]'\n",
      "[18:50:41] SMILES Parse Error: extra close parentheses while parsing: N=N(CCClCl)c1)CC)c()[O-]=[C@@H]2C(=O)I<SOS>NC(=O)\n",
      "[18:50:41] SMILES Parse Error: check for mistakes around position 14:\n",
      "[18:50:41] N=N(CCClCl)c1)CC)c()[O-]=[C@@H]2C(=O)I<SO\n",
      "[18:50:41] ~~~~~~~~~~~~~^\n",
      "[18:50:41] SMILES Parse Error: Failed parsing SMILES 'N=N(CCClCl)c1)CC)c()[O-]=[C@@H]2C(=O)I<SOS>NC(=O)' for input: 'N=N(CCClCl)c1)CC)c()[O-]=[C@@H]2C(=O)I<SOS>NC(=O)'\n",
      "[18:51:02] SMILES Parse Error: syntax error while parsing: ()c1nn[Li+][N+][C@]1[C@][nH][nH]1c1\n",
      "[18:51:02] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:51:02] ()c1nn[Li+][N+][C@]1[C@][nH][nH]1c1\n",
      "[18:51:02] ^\n",
      "[18:51:02] SMILES Parse Error: Failed parsing SMILES '()c1nn[Li+][N+][C@]1[C@][nH][nH]1c1' for input: '()c1nn[Li+][N+][C@]1[C@][nH][nH]1c1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generated Molecule 93:  (Status: Valid)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:51:15] SMILES Parse Error: extra close parentheses while parsing: [C@@H]cc2)cc1\n",
      "[18:51:15] SMILES Parse Error: check for mistakes around position 10:\n",
      "[18:51:15] [C@@H]cc2)cc1\n",
      "[18:51:15] ~~~~~~~~~^\n",
      "[18:51:15] SMILES Parse Error: Failed parsing SMILES '[C@@H]cc2)cc1' for input: '[C@@H]cc2)cc1'\n",
      "[18:51:24] SMILES Parse Error: syntax error while parsing: )=3(Cl\n",
      "[18:51:24] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:51:24] )=3(Cl\n",
      "[18:51:24] ^\n",
      "[18:51:24] SMILES Parse Error: Failed parsing SMILES ')=3(Cl' for input: ')=3(Cl'\n",
      "[18:52:08] SMILES Parse Error: syntax error while parsing: 2CN(F[C@@H]F[C@@]#2<SOS>O=C1S[C@@]\\cc1N[C@]NSc[Cl-][O-][Na+]I<SOS>c1cc\n",
      "[18:52:08] SMILES Parse Error: check for mistakes around position 1:\n",
      "[18:52:08] 2CN(F[C@@H]F[C@@]#2<SOS>O=C1S[C@@]\\cc1N[C\n",
      "[18:52:08] ^\n",
      "[18:52:08] SMILES Parse Error: Failed parsing SMILES '2CN(F[C@@H]F[C@@]#2<SOS>O=C1S[C@@]\\cc1N[C@]NSc[Cl-][O-][Na+]I<SOS>c1cc' for input: '2CN(F[C@@H]F[C@@]#2<SOS>O=C1S[C@@]\\cc1N[C@]NSc[Cl-][O-][Na+]I<SOS>c1cc'\n",
      "[18:52:19] non-ring atom 6 marked aromatic\n",
      "[18:53:05] SMILES Parse Error: syntax error while parsing: c[C@@][Na+]<SOS>Cl33[C@@H][O-]PIcc1)c1ccc2C1(C)s1<SOS>P#=NCN\n",
      "[18:53:05] SMILES Parse Error: check for mistakes around position 12:\n",
      "[18:53:05] c[C@@][Na+]<SOS>Cl33[C@@H][O-]PIcc1)c1ccc\n",
      "[18:53:05] ~~~~~~~~~~~^\n",
      "[18:53:05] SMILES Parse Error: Failed parsing SMILES 'c[C@@][Na+]<SOS>Cl33[C@@H][O-]PIcc1)c1ccc2C1(C)s1<SOS>P#=NCN' for input: 'c[C@@][Na+]<SOS>Cl33[C@@H][O-]PIcc1)c1ccc2C1(C)s1<SOS>P#=NCN'\n",
      "[18:53:50] SMILES Parse Error: syntax error while parsing: Cc1cc(S[PH][PH][N+]BrN1C1C(=O)=O[C@H](S=S(NBr<SOS>=FCl[C@]\n",
      "[18:53:50] SMILES Parse Error: check for mistakes around position 46:\n",
      "[18:53:50] C(=O)=O[C@H](S=S(NBr<SOS>=FCl[C@]\n",
      "[18:53:50] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[18:53:50] SMILES Parse Error: Failed parsing SMILES 'Cc1cc(S[PH][PH][N+]BrN1C1C(=O)=O[C@H](S=S(NBr<SOS>=FCl[C@]' for input: 'Cc1cc(S[PH][PH][N+]BrN1C1C(=O)=O[C@H](S=S(NBr<SOS>=FCl[C@]'\n",
      "[18:54:40] SMILES Parse Error: syntax error while parsing: c<SOS>S[PH][O-]CCCl)C1=S[C@@][N+][C@@H][O-](CN)=CC[C@H]13OBrc1c[nH][S+][N+]\n",
      "[18:54:40] SMILES Parse Error: check for mistakes around position 2:\n",
      "[18:54:40] c<SOS>S[PH][O-]CCCl)C1=S[C@@][N+][C@@H][O\n",
      "[18:54:40] ~^\n",
      "[18:54:40] SMILES Parse Error: Failed parsing SMILES 'c<SOS>S[PH][O-]CCCl)C1=S[C@@][N+][C@@H][O-](CN)=CC[C@H]13OBrc1c[nH][S+][N+]' for input: 'c<SOS>S[PH][O-]CCCl)C1=S[C@@][N+][C@@H][O-](CN)=CC[C@H]13OBrc1c[nH][S+][N+]'\n"
     ]
    }
   ],
   "source": [
    "N_MOLECS = 100\n",
    "valid_molecs = []\n",
    "# Initialize a master key once. Use a fixed seed for reproducibility.\n",
    "master_key = random.PRNGKey(1) \n",
    "\n",
    "# Normalize desired properties once\n",
    "desired_logp = normalize(2.0, min_logp, max_logp)\n",
    "desired_qed = normalize(0.7, min_qed, max_qed)\n",
    "desired_mw = normalize(250.0, min_mw, max_mw)\n",
    "props = jnp.array([desired_logp, desired_qed, desired_mw], dtype=jnp.float32)\n",
    "\n",
    "for n in range(N_MOLECS):\n",
    "    # *** Critical step: Split the master key for the current molecule's stochastic process ***\n",
    "    master_key, key_for_mol = random.split(master_key)\n",
    "    \n",
    "    # Use the new stochastic function\n",
    "    generated_bits = generate_molecule_stochastic(key_for_mol, props, combined_params)\n",
    "    generated_smiles = bits_to_smiles(generated_bits) \n",
    "    \n",
    "    # Now that the output is stochastic, you can proceed to validation.\n",
    "    \n",
    "    # ... Validation Code Here ... \n",
    "    # (See my previous suggestion for a full validation function)\n",
    "    # -----------------------------\n",
    "    mol = Chem.MolFromSmiles(generated_smiles)\n",
    "    if mol is not None:\n",
    "        validity = \"Valid\"\n",
    "        valid_molecs.append(generated_smiles)\n",
    "        # Obtain properties of valid molecules\n",
    "        print(f\" - Generated Molecule {n+1}: {generated_smiles} (Status: {validity})\")\n",
    "    else:\n",
    "        validity = \"Invalid\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total valid molecules generated: 7 out of 100\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_layers = 6\n",
    "h_local = 3\n",
    "prob_mask = NO MASK\n",
    "\n",
    "Epoch 1 | Loss = 0.6208 | Accuracy = 0.4185\n",
    "Epoch 2 | Loss = 0.5437 | Accuracy = 0.4909\n",
    "Epoch 3 | Loss = 0.5238 | Accuracy = 0.5092\n",
    "Epoch 4 | Loss = 0.5112 | Accuracy = 0.5222\n",
    "Epoch 5 | Loss = 0.5034 | Accuracy = 0.5330\n",
    "Epoch 6 | Loss = 0.5005 | Accuracy = 0.5372\n",
    "Epoch 7 | Loss = 0.4984 | Accuracy = 0.5426\n",
    "Epoch 8 | Loss = 0.4958 | Accuracy = 0.5470\n",
    "Epoch 9 | Loss = 0.4954 | Accuracy = 0.5492\n",
    "Epoch 10 | Loss = 0.4933 | Accuracy = 0.5497\n",
    "Epoch 11 | Loss = 0.4887 | Accuracy = 0.5585\n",
    "Epoch 12 | Loss = 0.4865 | Accuracy = 0.5625\n",
    "Epoch 13 | Loss = 0.4855 | Accuracy = 0.5594\n",
    "Epoch 14 | Loss = 0.4844 | Accuracy = 0.5634\n",
    "Epoch 15 | Loss = 0.4821 | Accuracy = 0.5645\n",
    "Epoch 16 | Loss = 0.4787 | Accuracy = 0.5690\n",
    "Epoch 17 | Loss = 0.4776 | Accuracy = 0.5752\n",
    "Epoch 18 | Loss = 0.4783 | Accuracy = 0.5689\n",
    "Epoch 19 | Loss = 0.4774 | Accuracy = 0.5783\n",
    "Epoch 20 | Loss = 0.4756 | Accuracy = 0.5784\n",
    "Epoch 21 | Loss = 0.4753 | Accuracy = 0.5751\n",
    "Epoch 22 | Loss = 0.4741 | Accuracy = 0.5789\n",
    "Epoch 23 | Loss = 0.4762 | Accuracy = 0.5767\n",
    "Epoch 24 | Loss = 0.4747 | Accuracy = 0.5771\n",
    "Epoch 25 | Loss = 0.4732 | Accuracy = 0.5787\n",
    "Epoch 26 | Loss = 0.4715 | Accuracy = 0.5852\n",
    "Epoch 27 | Loss = 0.4725 | Accuracy = 0.5805\n",
    "Epoch 28 | Loss = 0.4746 | Accuracy = 0.5792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/Users/ter/Apps/anaconda3/envs/tfm/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
    "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
    "/Users/ter/Apps/anaconda3/envs/tfm/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:122: UserWarning: Explicitly requested dtype <class 'jax.numpy.complex128'> requested in astype is not available, and will be truncated to dtype complex64. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
    "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
    "Epoch 1 | Loss = 0.5950 | Accuracy = 0.4449\n",
    "Epoch 2 | Loss = 0.5483 | Accuracy = 0.4865\n",
    "Epoch 3 | Loss = 0.5334 | Accuracy = 0.5034\n",
    "Epoch 4 | Loss = 0.5206 | Accuracy = 0.5211\n",
    "Epoch 5 | Loss = 0.5140 | Accuracy = 0.5264\n",
    "Epoch 6 | Loss = 0.5065 | Accuracy = 0.5418\n",
    "Epoch 7 | Loss = 0.5021 | Accuracy = 0.5492\n",
    "Epoch 8 | Loss = 0.5007 | Accuracy = 0.5510\n",
    "Epoch 9 | Loss = 0.4965 | Accuracy = 0.5588\n",
    "Epoch 10 | Loss = 0.4942 | Accuracy = 0.5562\n",
    "Epoch 11 | Loss = 0.4921 | Accuracy = 0.5642\n",
    "Epoch 12 | Loss = 0.4876 | Accuracy = 0.5738\n",
    "Epoch 13 | Loss = 0.4844 | Accuracy = 0.5769\n",
    "Epoch 14 | Loss = 0.4819 | Accuracy = 0.5794\n",
    "Epoch 15 | Loss = 0.4814 | Accuracy = 0.5753\n",
    "Epoch 16 | Loss = 0.4833 | Accuracy = 0.5763\n",
    "Epoch 17 | Loss = 0.4813 | Accuracy = 0.5841\n",
    "Epoch 18 | Loss = 0.4829 | Accuracy = 0.5808\n",
    "Epoch 19 | Loss = 0.4831 | Accuracy = 0.5795\n",
    "Epoch 20 | Loss = 0.4797 | Accuracy = 0.5832\n",
    "Epoch 21 | Loss = 0.4781 | Accuracy = 0.5861\n",
    "Epoch 22 | Loss = 0.4751 | Accuracy = 0.5866\n",
    "Epoch 23 | Loss = 0.4750 | Accuracy = 0.5891\n",
    "Epoch 24 | Loss = 0.4762 | Accuracy = 0.5872\n",
    "Epoch 25 | Loss = 0.4748 | Accuracy = 0.5912"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h=2\n",
    "\n",
    "Epoch 1 | Loss = 2.6945 | Accuracy = 0.4050 \n",
    "Epoch 2 | Loss = 2.4173 | Accuracy = 0.4816 \n",
    "Epoch 3 | Loss = 2.3229 | Accuracy = 0.5047 \n",
    "Epoch 4 | Loss = 2.2768 | Accuracy = 0.5220\n",
    "Epoch 5 | Loss = 2.2505 | Accuracy = 0.5267 \n",
    "Epoch 6 | Loss = 2.2214 | Accuracy = 0.5399 \n",
    "Epoch 7 | Loss = 2.2051 | Accuracy = 0.5448 \n",
    "Epoch 8 | Loss = 2.1918 | Accuracy = 0.5523 \n",
    "Epoch 9 | Loss = 2.1790 | Accuracy = 0.5544 \n",
    "Epoch 10 | Loss = 2.1683 | Accuracy = 0.5577 \n",
    "Epoch 11 | Loss = 2.1654 | Accuracy = 0.5582 \n",
    "Epoch 12 | Loss = 2.1519 | Accuracy = 0.5617 \n",
    "Epoch 13 | Loss = 2.1452 | Accuracy = 0.5647 \n",
    "Epoch 14 | Loss = 2.1371 | Accuracy = 0.5670 \n",
    "Epoch 15 | Loss = 2.1380 | Accuracy = 0.5630 \n",
    "Epoch 16 | Loss = 2.1330 | Accuracy = 0.5654 \n",
    "Epoch 17 | Loss = 2.1251 | Accuracy = 0.5661 \n",
    "Epoch 18 | Loss = 2.1189 | Accuracy = 0.5703 \n",
    "Epoch 19 | Loss = 2.1176 | Accuracy = 0.5718 \n",
    "Epoch 20 | Loss = 2.1152 | Accuracy = 0.5698 \n",
    "Epoch 21 | Loss = 2.1162 | Accuracy = 0.5682 \n",
    "Epoch 22 | Loss = 2.1117 | Accuracy = 0.5704 \n",
    "Epoch 23 | Loss = 2.1126 | Accuracy = 0.5729 \n",
    "Epoch 24 | Loss = 2.1097 | Accuracy = 0.5735 \n",
    "Epoch 25 | Loss = 2.1040 | Accuracy = 0.5756 \n",
    "Epoch 26 | Loss = 2.1001 | Accuracy = 0.5751 \n",
    "Epoch 27 | Loss = 2.0959 | Accuracy = 0.5794 \n",
    "Epoch 28 | Loss = 2.0881 | Accuracy = 0.5808 \n",
    "Epoch 29 | Loss = 2.0891 | Accuracy = 0.5806 \n",
    "Epoch 30 | Loss = 2.0869 | Accuracy = 0.5808 \n",
    "Epoch 31 | Loss = 2.0843 | Accuracy = 0.5855 \n",
    "Epoch 32 | Loss = 2.0859 | Accuracy = 0.5839 \n",
    "Epoch 33 | Loss = 2.0841 | Accuracy = 0.5830"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
